{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa082810",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Predicting the ∆∆G of single point mutations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3fcf52-0c61-4955-9396-d6ae6210d5f1",
   "metadata": {},
   "source": [
    "## The Heatmap, or Respect and Audience Again.\n",
    "<center><img src=\"img/Slide.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c534e86a",
   "metadata": {},
   "source": [
    "## Introduction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48641f76-1303-45a5-a396-f2bbe9e1b1e9",
   "metadata": {},
   "source": [
    "<center><img src=\"img/img1.jpeg\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef95f58",
   "metadata": {},
   "source": [
    "Accurately estimating the thermodynamic cost of a mutation is a building block in protein engineering and design. We will take a small protein and try to make it better, or at least more stable. To achieve this, we will carry out \"alchemical\" mutations during simulations and compute the corresponding free energy changes. If we do this both in the folded and unfolded states and compute the difference between them, we can estimate the difference in stability between the wild type and the mutant, as shown in this thermodynamic cycle:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0be3778-d261-4335-ac88-bafd24ca06fa",
   "metadata": {},
   "source": [
    "<center><img src=\"img/cycle.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4e2154-dac4-41ef-b17f-498ed01e9bd9",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\Large G=H - TS \\\\\n",
    "\\Large {\\Delta}G_{fold} = (H_{unfold} - H_{fold})-T*(S_{unfold} - S_{fold}) \\\\\n",
    "\\Large {\\Delta}{\\Delta}G = {\\Delta}G_{fold_{MT}} - {\\Delta}G_{fold_{  WT}}\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd086e73",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Objectives\n",
    "1. Setup a parameters\n",
    "2. Prepare files\n",
    "3. Compute the ∆∆G of mutation\n",
    "4. Analyze contributions to the change in stability\n",
    "5. Visualize the model in PyMOL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003315f8-4274-47d2-840c-5f662f8bffc9",
   "metadata": {},
   "source": [
    "## Loading required dependencies\n",
    "Proper work with the notebook requires the following modules:\n",
    "1. PyRosetta/4.release-384-gompi-2022a\n",
    "2. SciPy-bundle/2022.05-foss-2022a\n",
    "3. py3Dmol/2.0.1.post1-GCCcore-11.3.0\n",
    "4. Biopython/1.79-foss-2022a\n",
    "5. matplotlib/3.5.2-foss-2022a\n",
    "6. Seaborn/0.12.1-foss-2022a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f427f602",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup\n",
    "The first step is to initialize __configs__ _class_ and load the protein of interest. \n",
    "\n",
    "Mandatory class attributes:\n",
    "1. __PDB_filename__ - the full (with .pdb extension) protein filename\n",
    "2. __mut__ - a list of investigated mutations in Python format\n",
    "3. __aa_list__ -  a list of tested mutations in each position provided in \"mut\" list\n",
    "4. __jobname__ - a temporary folder which will contains some intermediate results\n",
    "\n",
    "Optional class atributes (already initialized by default and mostly often used values):\n",
    "1. __num_threads__ - number of threads, set 0 to maximum available physical cores\n",
    "2. __ntraj__ - the amount of trajectories to structure relaxation before ΔΔG calc\n",
    "3. __nstruct__ - the value of relaxed structures from each trajectory\n",
    "4. __relax_scorefxn__ - supply a different score functon from the Rosetta default\n",
    "5. __ddg_iterations__ - \n",
    "6. __force_iterations__ - if this flag is on the protocol will stop when the results converge on a score\n",
    "7. __ddg_score_cutoff__ - if the lowest energy scores are within this cutoff the protocol will end early\n",
    "8. __ddg_dump_pdbs__ - you can save mutants PDBs if you want\n",
    "9. __ddg_bbnbrs__ - bb dof, suggestion: i-1, i, i+1\n",
    "10. __fa_max_dis__ - modify fa_atr and fa_sol behavior, really important for protein stability\n",
    "11. __ddg_scorefxn__ - supply a different score functon from the Rosetta default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "020eb7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class configs(object):\n",
    "  def __init__(self):\n",
    "\n",
    "    self.PDB_filename = 'peptide.pdb'\n",
    "    self.mut = ['L1', 'Y2', 'I3', 'Q4', 'W5', 'L6', 'K7', 'D8']\n",
    "    self.aa_list = ['M', 'F','G', 'A', 'I', 'P', 'S']\n",
    "    self.jobname = 'jobname_peptide'\n",
    "    \n",
    "    self.num_threads = 0\n",
    "    self.ntraj = 20\n",
    "    self.nstruct = 2\n",
    "    self.relax_scorefxn = 'ref2015_cart'\n",
    "    self.ddg_iterations = 3\n",
    "    self.force_iterations = False\n",
    "    self.ddg_score_cutoff = 1.0\n",
    "    self.ddg_dump_pdbs = True\n",
    "    self.ddg_bbnbrs = 1\n",
    "    self.fa_max_dis = 9.0\n",
    "    self.ddg_scorefxn = 'ref2015_cart'\n",
    "    \n",
    "    import os\n",
    "    if not os.path.exists(self.PDB_filename):\n",
    "        raise Exception(f\"Sorry, the file with name {self.PDB_filename[:-4]} was not found.\")\n",
    "    \n",
    "    if self.num_threads == 0:\n",
    "        import os \n",
    "        nslots = int(os.environ['SLURM_CPUS_PER_TASK'])\n",
    "        self.num_threads = nslots\n",
    "    self.coord_cst = True\n",
    "    py_flags = \"-ddg:mut_file mutfile -ddg:iterations \"\n",
    "    py_flags += str(self.ddg_iterations) \n",
    "    py_flags += \" -force_iterations \"\n",
    "    py_flags += str(self.force_iterations).lower()\n",
    "    py_flags += \" -ddg::score_cutoff \"\n",
    "    py_flags += str(self.ddg_score_cutoff)\n",
    "    py_flags += \" -ddg::cartesian -ddg::dump_pdbs \"\n",
    "    py_flags += str(self.ddg_dump_pdbs).lower()\n",
    "    py_flags += \" -ddg:bbnbrs \"\n",
    "    py_flags += str(self.ddg_bbnbrs)\n",
    "    py_flags += \" -fa_max_dis \"\n",
    "    py_flags += str(self.fa_max_dis)\n",
    "    py_flags += \" -score:weights \"\n",
    "    py_flags += str(self.ddg_scorefxn)\n",
    "    py_flags += \".wts\"\n",
    "    self.py_flags = py_flags\n",
    "    import os\n",
    "    self.working_dir = os.getcwd()\n",
    "    \n",
    "  def back(self):\n",
    "        import os\n",
    "        os.chdir(self.working_dir)\n",
    "    \n",
    "conf = configs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daccfb6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preparation of storage hierarchy \n",
    "\n",
    "At this moment the following file structure is presented:\n",
    "- ddG_notebook.ipynb\n",
    "- PDB_filename.pdb\n",
    "- __img__\n",
    "    - some illustrative images\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8726cf9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cleaning PDB file\n",
    "Let's prepare our temporary __file structure hierarchy__ and clean protein file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b44cb297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preparation(conf, clean_mode = 'grep'):\n",
    "    name, ntraj = conf.PDB_filename, conf.ntraj\n",
    "    import os\n",
    "    current_dir = os.getcwd()\n",
    "    if not os.path.exists(conf.jobname):\n",
    "        os.mkdir(conf.jobname)\n",
    "    os.chdir(conf.jobname)\n",
    "    pdb_name = name[:-4]\n",
    "    \n",
    "    match clean_mode:\n",
    "        case 'grep':\n",
    "            os.system(f'''grep \"^ATOM\" ../{pdb_name}.pdb > {pdb_name}_clean.pdb''')\n",
    "        case 'pyrosetta':\n",
    "            import pyrosetta\n",
    "            pyrosetta.init(\"-mute all\")\n",
    "            pyrosetta.toolbox.cleanATOM(f\"../{conf.PDB_filename}\")\n",
    "            os.rename(f'../{pdb_name}.clean.pdb', f'{pdb_name}_clean.pdb')\n",
    "        case 'custom':\n",
    "            from script.clean_pdb import main as clean_pdb\n",
    "            clean_pdb(f'../{pdb_name}.pdb')\n",
    "            os.rename(f'../{conf.PDB_filename}.clean.pdb', f'{pdb_name}_clean.pdb')\n",
    "    \n",
    "    for i in range(1, ntraj + 1):\n",
    "        if not os.path.exists(str(i)):\n",
    "            os.mkdir(str(i))\n",
    "            os.system(f'touch {str(i)}/stdout.txt')\n",
    "    os.chdir(current_dir)\n",
    "    return 0\n",
    "\n",
    "preparation(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3623ab61",
   "metadata": {},
   "source": [
    "The inner structure of __jobname__ directore is following:\n",
    "- __jobname__\n",
    "    - PDB_filename_clean.pdb\n",
    "    - __$i^{th}$ trajectory folder__\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb67d2a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Relaxation\n",
    "Let's look at a very simplified example of the global extrema search approach and understand the reason for choosing more than just a couple of independent trajectories during the search.\n",
    "\n",
    "Below is an animation showing 4 different trajectories of searching for a global extremum on a given function. The function is the __inverse__ height of the terrain near Mount Washington, as a function of the x-y location. In order to find the top of Mount Washington, we minimize the objective function that is the negative of the height. (The Mount Washington in this example is the highest peak in the northeastern United States.)\n",
    "\n",
    "The animation is a great example of finding different global extrema, even in a situation where there is only one global minimum value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb89e97-31e1-48d0-bd5f-51c879be0b41",
   "metadata": {},
   "source": [
    "\"<table><tr><td><img src='img/surface.gif'></td><td><img src='img/3D.gif'></td></tr></table>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d8076d-6337-4c14-a523-45c17b22cbfa",
   "metadata": {},
   "source": [
    "\n",
    "In the next cell we will initialize two funcitons.\n",
    "\n",
    "The function __relax_job__ is providing relaxiation of protein structure.\n",
    "\n",
    "def __run_relax_job_parallel__ is wrapper function for running calculation in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "770e3234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relax_job(args):\n",
    "    name_clean, nstruct, scorefxn_name, dest = args\n",
    "    import os\n",
    "    import logging\n",
    "    current_dir = os.getcwd()\n",
    "    os.chdir(dest)\n",
    "    logging.basicConfig(filename='stdout.txt', level=logging.INFO)\n",
    "    import pyrosetta\n",
    "    pyrosetta.init()\n",
    "    pose = pyrosetta.pose_from_pdb('../' + name_clean)\n",
    "    scorefxn = pyrosetta.create_score_function(scorefxn_name)\n",
    "    xml = pyrosetta.rosetta.protocols.rosetta_scripts.XmlObjects.create_from_string(\"\"\"\n",
    "    <ROSETTASCRIPTS>\n",
    "        <SCOREFXNS>\n",
    "        <ScoreFunction name=\"SFX1\" weights=\"ref2015_cart\">\n",
    "           <Reweight scoretype=\"coordinate_constraint\" weight=\"1.0\"/>\n",
    "        </ScoreFunction>\n",
    "        </SCOREFXNS>\n",
    "        <RESIDUE_SELECTORS>\n",
    "        </RESIDUE_SELECTORS>\n",
    "        <TASKOPERATIONS>\n",
    "        </TASKOPERATIONS>\n",
    "        <FILTERS>\n",
    "        </FILTERS>\n",
    "        <MOVERS>\n",
    "           <AtomCoordinateCstMover name=\"coord_cst\" />\n",
    "           <FastRelax name=\"relax\" cartesian=\"true\" scorefxn=\"SFX1\" />\n",
    "        </MOVERS>\n",
    "        <APPLY_TO_POSE/>\n",
    "        <PROTOCOLS>\n",
    "           <Add mover=\"coord_cst\" />\n",
    "           <Add mover=\"relax\" />\n",
    "        </PROTOCOLS>\n",
    "    </ROSETTASCRIPTS>\n",
    "    \"\"\").get_mover(\"ParsedProtocol\")\n",
    "    \n",
    "    working_dir = os.getcwd()\n",
    "    output_dir = dest\n",
    "    jd = pyrosetta.toolbox.py_jobdistributor.PyJobDistributor(pdb_name=name_clean[:-4], nstruct=nstruct, scorefxn=scorefxn)\n",
    "    jd.native_pose = pose\n",
    "    while not jd.job_complete:\n",
    "        test_pose = pose.clone()\n",
    "        xml.apply(test_pose)\n",
    "        jd.output_decoy(test_pose)\n",
    "    os.chdir(current_dir)\n",
    "    return 0\n",
    "\n",
    "\n",
    "def run_relax_job_parallel(conf):\n",
    "    name, nstruct, scorefxn_name, num_th = conf.PDB_filename, conf.nstruct, conf.relax_scorefxn, conf.num_threads\n",
    "    name = name[:-4] + '_clean.pdb'\n",
    "    ntraj = conf.ntraj\n",
    "    if not conf.coord_cst:\n",
    "        conf.jobname = conf.jobname + '_without_cst'\n",
    "        preparation(conf)\n",
    "    from multiprocessing.pool import Pool\n",
    "    import os\n",
    "    os.chdir(conf.jobname)\n",
    "    args = [(name, nstruct, scorefxn_name, str(i)) for i in range(1, ntraj + 1)]\n",
    "    with Pool(num_th) as pool:\n",
    "        pool.map(relax_job, args, chunksize=1)\n",
    "    os.chdir('../')\n",
    "    if not conf.coord_cst:\n",
    "        conf.jobname = conf.jobname[:-12]\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfff2108",
   "metadata": {},
   "source": [
    "Now, we will run relaxiation of structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8cc396",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_relax_job_parallel(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091c846d",
   "metadata": {},
   "source": [
    "Inside the temporary folder, that was created at the begining we have __ntraj__ number of folders, and in each folder __nstruct__ PDBs. Additionally, there are score files with extension _*.fasc_.\n",
    "\n",
    "- __jobname__\n",
    "    - PDB_filename_clean.pdb\n",
    "    - __$i^{th}$ trajectory folder__\n",
    "        - stdout.txt\n",
    "        - PDB_filename_*.pdb\n",
    "        - PDB_filename.fasc\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb2c5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code here relax without coordinate constraints\n",
    "def relax_job(args):\n",
    "    name_clean, nstruct, scorefxn_name, dest = args\n",
    "    import os\n",
    "    import logging\n",
    "    current_dir = os.getcwd()\n",
    "    os.chdir(dest)\n",
    "    logging.basicConfig(filename='stdout.txt', level=logging.INFO)\n",
    "    import pyrosetta\n",
    "    pyrosetta.init()\n",
    "    pose = pyrosetta.pose_from_pdb('../' + name_clean)\n",
    "    scorefxn = pyrosetta.create_score_function(scorefxn_name)\n",
    "    xml = pyrosetta.rosetta.protocols.rosetta_scripts.XmlObjects.create_from_string(\"\"\"\n",
    "    <ROSETTASCRIPTS>\n",
    "        <SCOREFXNS>\n",
    "        <ScoreFunction name=\"SFX1\" weights=\"ref2015_cart\">\n",
    "           <Reweight scoretype=\"coordinate_constraint\" weight=\"1.0\"/>\n",
    "        </ScoreFunction>\n",
    "        </SCOREFXNS>\n",
    "        <RESIDUE_SELECTORS>\n",
    "        </RESIDUE_SELECTORS>\n",
    "        <TASKOPERATIONS>\n",
    "        </TASKOPERATIONS>\n",
    "        <FILTERS>\n",
    "        </FILTERS>\n",
    "        <MOVERS>\n",
    "           <AtomCoordinateCstMover name=\"coord_cst\" />\n",
    "           <FastRelax name=\"relax\" cartesian=\"true\" scorefxn=\"SFX1\" />\n",
    "        </MOVERS>\n",
    "        <APPLY_TO_POSE/>\n",
    "        <PROTOCOLS>\n",
    "           <Add mover=\"relax\" />\n",
    "        </PROTOCOLS>\n",
    "    </ROSETTASCRIPTS>\n",
    "    \"\"\").get_mover(\"ParsedProtocol\")\n",
    "    \n",
    "    working_dir = os.getcwd()\n",
    "    output_dir = dest\n",
    "    jd = pyrosetta.toolbox.py_jobdistributor.PyJobDistributor(pdb_name=name_clean[:-4], nstruct=nstruct, scorefxn=scorefxn)\n",
    "    jd.native_pose = pose\n",
    "    while not jd.job_complete:\n",
    "        test_pose = pose.clone()\n",
    "        xml.apply(test_pose)\n",
    "        jd.output_decoy(test_pose)\n",
    "    os.chdir(current_dir)\n",
    "    return 0\n",
    "\n",
    "\n",
    "def run_relax_job_parallel(conf):\n",
    "    name, nstruct, scorefxn_name, num_th = conf.PDB_filename, conf.nstruct, conf.relax_scorefxn, conf.num_threads\n",
    "    name = name[:-4] + '_clean.pdb'\n",
    "    ntraj = conf.ntraj\n",
    "    \n",
    "    # Let's decrease number of trajectories and produced structures by 10 and 2, respectively.\n",
    "    ntraj = ntraj // 10\n",
    "    nstruct = nstruct // 2\n",
    "    \n",
    "    if not conf.coord_cst:\n",
    "        conf.jobname = conf.jobname + '_without_cst'\n",
    "        preparation(conf)\n",
    "    from multiprocessing.pool import Pool\n",
    "    import os\n",
    "    os.chdir(conf.jobname)\n",
    "    args = [(name, nstruct, scorefxn_name, str(i)) for i in range(1, ntraj + 1)]\n",
    "    with Pool(num_th) as pool:\n",
    "        pool.map(relax_job, args, chunksize=1)\n",
    "    os.chdir('../')\n",
    "    if not conf.coord_cst:\n",
    "        conf.jobname = conf.jobname[:-12]\n",
    "    return 0\n",
    "\n",
    "conf.coord_cst = False\n",
    "run_relax_job_parallel(conf)\n",
    "conf.coord_cst = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04810d5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Scoring\n",
    "We have to choose the structure with the lowest energy score measured in Rosetta Energy Units (REU). \n",
    "The following function is parsing all generated _*.fasc_. score files and return __the path__ to PDB with lowest energy.\n",
    "\n",
    "We will store the returned path as an atribute of __config class__ object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5753f32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('relaxed_peptide_clean_0.pdb', -35.55381183801366)\n"
     ]
    }
   ],
   "source": [
    "def get_scores(conf):\n",
    "    conf.back()\n",
    "    import pandas as pd\n",
    "    import glob\n",
    "    import os\n",
    "    os.chdir(conf.jobname)\n",
    "    dall_scores = pd.DataFrame(columns = ['description', 'total_score'])\n",
    "    for f in glob.glob('*/*.fasc'):\n",
    "        pth = str(f).split('/')[0]\n",
    "        with open(f, 'r') as file:\n",
    "            tmp = pd.DataFrame()\n",
    "            for line in file.readlines():\n",
    "                total_score = float(line[line.find('total_score'):line.find('\"yhh_planarity')].split(':')[1].strip()[:-1])\n",
    "                name_decoy = line[line.find(\"decoy\"):line.find(', \"filename\"')].split(':')[-1].split('\"')[1]\n",
    "                dic = {'description': [pth + '/' + name_decoy], 'total_score':[total_score]}\n",
    "                tmp = pd.DataFrame(dic)\n",
    "                dall_scores = pd.concat([dall_scores, tmp], ignore_index = True)\n",
    "\n",
    "    dres = dall_scores[dall_scores.total_score == dall_scores.total_score.min()]\n",
    "    source  = list(dres.description)[0]\n",
    "    pdb = source.split('/')[1]\n",
    "    if not os.path.exists('mutations'):\n",
    "        os.mkdir('mutations')\n",
    "    target = \"mutations/relaxed_\"  + pdb\n",
    "    os.system(f'cp {source} {target}')\n",
    "    os.chdir('../')\n",
    "    return target.split('/')[-1], dall_scores.total_score.min()\n",
    "\n",
    "\n",
    "conf.cleanaxed_pdb, min_REU = get_scores(conf)\n",
    "print((conf.cleanaxed_pdb, min_REU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d405af2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exercise: extract the lowest energy score for structures \n",
    "### obtained without coordinate constaraints \n",
    "\n",
    "# Solution\n",
    "\n",
    "def get_scores(conf):\n",
    "    conf.back()\n",
    "    import pandas as pd\n",
    "    import glob\n",
    "    import os\n",
    "    os.chdir(conf.jobname)\n",
    "    dall_scores = pd.DataFrame(columns = ['description', 'total_score'])\n",
    "    for f in glob.glob('*/*.fasc'):\n",
    "        pth = str(f).split('/')[0]\n",
    "        with open(f, 'r') as file:\n",
    "            tmp = pd.DataFrame()\n",
    "            for line in file.readlines():\n",
    "                total_score = float(line[line.find('total_score'):line.find('\"yhh_planarity')].split(':')[1].strip()[:-1])\n",
    "                name_decoy = line[line.find(\"decoy\"):line.find(', \"filename\"')].split(':')[-1].split('\"')[1]\n",
    "                dic = {'description': [pth + '/' + name_decoy], 'total_score':[total_score]}\n",
    "                tmp = pd.DataFrame(dic)\n",
    "                dall_scores = pd.concat([dall_scores, tmp], ignore_index = True)\n",
    "\n",
    "    dres = dall_scores[dall_scores.total_score == dall_scores.total_score.min()]\n",
    "    source  = list(dres.description)[0]\n",
    "    pdb = source.split('/')[1]\n",
    "    if not os.path.exists('mutations'):\n",
    "        os.mkdir('mutations')\n",
    "    target = \"mutations/relaxed_\"  + pdb\n",
    "    os.system(f'cp {source} {target}')\n",
    "    os.chdir('../')\n",
    "    return target.split('/')[-1], dall_scores.total_score.min()\n",
    "\n",
    "init_jobname = conf.jobname\n",
    "conf.jobname = conf.jobname + '_without_cst'\n",
    "print(get_scores(conf))\n",
    "conf.jobname = init_jobname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac308ef4-e063-4dfb-9492-4bccaa0f0121",
   "metadata": {},
   "source": [
    "Let's calc the RMSD value between initial and relaxed structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f519e6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Bio.PDB\n",
    "import os\n",
    "\n",
    "start_id = 1\n",
    "end_id   = 999\n",
    "atoms_to_be_aligned = range(start_id, end_id + 1)\n",
    "\n",
    "# Start the parser\n",
    "pdb_parser = Bio.PDB.PDBParser(QUIET = True)\n",
    "\n",
    "# Get the structures\n",
    "ref_structure = pdb_parser.get_structure(\"reference\", f'{conf.jobname}/{conf.PDB_filename[:-4]}_clean.pdb')\n",
    "sample_structure = pdb_parser.get_structure(\"sample\", f'{conf.jobname}/mutations/{conf.cleanaxed_pdb}')\n",
    "\n",
    "\n",
    "ref_model    = ref_structure[0]\n",
    "sample_model = sample_structure[0]\n",
    "\n",
    "# Make a list of the atoms (in the structures) you wish to align.\n",
    "# In this case we use CA atoms whose index is in the specified range\n",
    "ref_atoms = []\n",
    "sample_atoms = []\n",
    "\n",
    "# Iterate of all chains in the model in order to find all residues\n",
    "for ref_chain in ref_model:\n",
    "  # Iterate of all residues in each model in order to find proper atoms\n",
    "  for ref_res in ref_chain:\n",
    "    # Check if residue number ( .get_id() ) is in the list\n",
    "    if ref_res.get_id()[1] in atoms_to_be_aligned:\n",
    "      # Append CA atom to list\n",
    "      ref_atoms.append(ref_res['CA'])\n",
    "\n",
    "# Do the same for the sample structure\n",
    "for sample_chain in sample_model:\n",
    "  for sample_res in sample_chain:\n",
    "    if sample_res.get_id()[1] in atoms_to_be_aligned:\n",
    "      sample_atoms.append(sample_res['CA'])\n",
    "\n",
    "# Now we initiate the superimposer:\n",
    "super_imposer = Bio.PDB.Superimposer()\n",
    "super_imposer.set_atoms(ref_atoms, sample_atoms)\n",
    "super_imposer.apply(sample_model.get_atoms())\n",
    "\n",
    "# Print RMSD:\n",
    "print('The calculated RMSD is:')\n",
    "print (str(super_imposer.rms) + ' Å')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bff329-3336-4f7d-aafd-25e0111a0a48",
   "metadata": {},
   "source": [
    "Now, we are intrested in visualization of our structures by py3Dmol library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed2cde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import py3Dmol\n",
    "import glob\n",
    "view=py3Dmol.view()\n",
    "#The following lines are used to add the addModel class\n",
    "#to read the PDB files of chain Clean and Relaxed\n",
    "view.addModel(open(f'{conf.jobname}/{conf.PDB_filename[:-4]}_clean.pdb', 'r').read(),'pdb')\n",
    "\n",
    "view.addModel(open(f'{conf.jobname}/mutations/{conf.cleanaxed_pdb}', 'r').read(),'pdb')\n",
    "\n",
    "view.addModel(open(glob.glob(f'{conf.jobname}_without_cst/mutations/*.pdb')[0], 'r').read(),'pdb')\n",
    "#Zooming into all visualized structures \n",
    "view.zoomTo()\n",
    "#Here we set the background color as white\n",
    "view.setBackgroundColor('white')\n",
    "#Here we set the visualization style for Clean and Relaxed\n",
    "view.setStyle({'model': 0},{'cartoon': {'color':'purple'}})\n",
    "view.setStyle({'model': 1},{'cartoon': {'color':'yellow'}})\n",
    "view.setStyle({'model': 2},{'cartoon': {'color':'blue'}})\n",
    "\n",
    "\n",
    "print(\"Initial structure: \\t\\t\\t\\t\\t purple.\")\n",
    "print(\"Relaxed with coordinate constraints structure:\\t\\t yellow.\")\n",
    "print(\"Relaxed without coordinate constraints structure: \\t blue.\")\n",
    "\n",
    "view.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9c7821-e054-4d6c-a931-55be8a1372f5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "__Exercise__: plot scatter_plot RMSD vs total score, and highlight the dot with the lowest energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6428e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import glob\n",
    "%matplotlib inline\n",
    "TSs = []\n",
    "RMSDs = []\n",
    "for file in glob.glob(f'{conf.jobname}/*/*.fasc'):\n",
    "    with open(file, 'r') as fasc:\n",
    "        for line in fasc.readlines ():\n",
    "            rmsd = float(line[line.find('rmsd'):-2].split(':')[-1])\n",
    "            total_score = float(line[line.find('total_score'):line.find('\"yhh_planarity')].split(':')[1].strip() [:-1])\n",
    "            TSs += [total_score]\n",
    "            RMSDs += [rmsd]\n",
    "TSs = np.array(TSs)\n",
    "RMSDs = np.array(RMSDs)\n",
    "                                                                                                                  \n",
    "colors = ['k'] * len(TSs)\n",
    "colors[np.argmin(TSs)] = 'r'\n",
    "size = [15] * len(TSs)\n",
    "size[np.argmin(TSs)] = 100\n",
    "fig,ax = plt.subplots()\n",
    "ax.scatter(TSs, RMSDs, c=colors, s = size)\n",
    "ax.scatter( [], [], c='k', label='loweset energy score') \n",
    "ax.scatter( [], [], c='r', label= 'Other scores') \n",
    "#ax.legend(loc='best')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a877398",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Mutfile's preparation\n",
    "From this point, we obtain the relaxed protein structure that prepared for introducing mutations and analyzing them.\n",
    "\n",
    "Let's create a little bit more new subfolders and put __mutfile__'s for as an instruction for PyRosetta mutation script.\n",
    "<br><br>\n",
    "\n",
    "Each __mutfile__ consists the following lines:\n",
    "\n",
    "total 1 &emsp;# this is the total number of mutations being made.\n",
    "<br>\n",
    "1 &emsp; &emsp;&emsp;#the number of mutations\n",
    "<br>\n",
    "G 1 A &emsp; # the wild-type aa, the residue number, and the mutant aa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47a38b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mutfiles_preparation(conf):\n",
    "    import os\n",
    "    conf.back()\n",
    "    os.chdir(f'{conf.jobname}/mutations')\n",
    "    mut = conf.mut\n",
    "    aa_list = conf.aa_list\n",
    "    mutations = []\n",
    "    for aa in range(0, len(mut)):\n",
    "        pos = mut[aa]\n",
    "        AA = mut[aa][0]\n",
    "        if not os.path.exists(pos):\n",
    "            os.makedirs(pos)\n",
    "        for m in aa_list:\n",
    "            if m != AA:\n",
    "                mutation = pos+m\n",
    "                mutations.append(mutation)\n",
    "                if not os.path.exists(pos+\"/\"+mutation):\n",
    "                    os.makedirs(pos+\"/\"+mutation)\n",
    "                with open(pos+\"/\"+mutation+\"/mutfile\",'w') as mut_file:\n",
    "                    mut_file.write(\"total 1\\n\")\n",
    "                    mut_file.write(\"1\\n\")\n",
    "                    mut_file.write(\"%s %d %s\\n\" %(AA, int(mut[aa][1:]), m))\n",
    "    os.chdir('../../')\n",
    "    return 0\n",
    "\n",
    "\n",
    "mutfiles_preparation(conf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c3aa94",
   "metadata": {},
   "source": [
    "The __jobname__ folder structure now is looking like this:\n",
    "\n",
    "- __jobname__\n",
    "    - PDB_filename_clean.pdb\n",
    "    - __$i^{th}$ trajectory folder__\n",
    "        - stdout.txt\n",
    "        - PDB_filename_*.pdb\n",
    "        - PDB_filename.fasc\n",
    "    - __mutations__\n",
    "        - relaxed_PDB_filename_clean_$i$.pdb\n",
    "        - __$i^{th}$__ mutation folder along __mut__ array\n",
    "            - __$j^{th}$__ resulted mut folder along __aa_list__\n",
    "                - mutfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b16bdc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ${\\Delta}{\\Delta} G$ calculation\n",
    "In the next cell we will initialize two funciton.\n",
    "\n",
    "def __ddg_job__ is made for estimating $\\Delta\\Delta G$ per one-point mutation. \n",
    "\n",
    "def __run_ddg_calc_parallel__ is wrapper function for running calculation in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6acfe010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddg_job(args):\n",
    "    pdb_name, py_flags, dest = args\n",
    "    import os\n",
    "    import logging\n",
    "    current_dir = os.getcwd()\n",
    "    os.chdir(dest)\n",
    "    logging.basicConfig(filename='stdout.txt', level=logging.INFO)\n",
    "    import pyrosetta\n",
    "    \n",
    "    pyrosetta.init(py_flags)\n",
    "    pose = pyrosetta.pose_from_pdb('../../' + pdb_name)\n",
    "    pyrosetta.rosetta.protocols.ddg.CartesianddG.run(pose)\n",
    "    os.chdir(current_dir)\n",
    "    return 0\n",
    "\n",
    "def run_ddg_calc_parallel(conf):\n",
    "    conf.back()\n",
    "    import os \n",
    "    os.chdir(f'{conf.jobname}/mutations')\n",
    "    name = conf.cleanaxed_pdb\n",
    "    num_th = conf.num_threads\n",
    "    import glob\n",
    "    args = [(name, conf.py_flags, x[:-7]) for x in glob.glob('*/*/mutfile')]\n",
    "    from multiprocessing.pool import Pool\n",
    "    with Pool(num_th) as pool:\n",
    "        pool.map(ddg_job, args, chunksize=1)\n",
    "    os.chdir('../../')\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d59466",
   "metadata": {},
   "source": [
    "Now, we will run $\\Delta\\Delta G$ calculation for all one-point mutations that were selected in __config__ class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fafb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ddg_calc_parallel(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ee8ad3",
   "metadata": {},
   "source": [
    "Let's analyze just generated outputs. We are intrested in __mutfile.ddg__  files.\n",
    "\n",
    "The __jobname__ folder structure now is looking like this:\n",
    "\n",
    "- __jobname__\n",
    "    - PDB_filename_clean.pdb\n",
    "    - __$i^{th}$ trajectory folder__\n",
    "        - stdout.txt\n",
    "        - PDB_filename_*.pdb\n",
    "        - PDB_filename.fasc\n",
    "    - __mutations__\n",
    "        - relaxed_PDB_filename_clean_$i$.pdb\n",
    "        - __$i^{th}$__ mutation folder along __mut__ array\n",
    "            - __$j^{th}$__ resulted mut folder along __aa_list__\n",
    "                - mutfile\n",
    "                - mutfile.ddg\n",
    "                - stdout.txt\n",
    "    \n",
    "Based on the information from __mutfile.ddg__, the $\\Delta\\Delta G$ will be calculated as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\Large{\\Delta}{\\Delta}G={\\frac {\\sum_{i}^{} MUT\\_total\\_score_{i} \\\\}{ddg\\_iterations} }-{\\frac {\\sum_{i}^{} WT\\_total\\_score_{i} \\\\}{ddg\\_iterations} }\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd28173e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Analyzing \n",
    "The bellow function generates __*.csv__ file in root directory with $\\Delta\\Delta G$ values measured in REU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6bc2b6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyze_ssm(conf):\n",
    "    conf.back()\n",
    "    mut = conf.mut\n",
    "    aa_list = conf.aa_list\n",
    "    import os\n",
    "    import glob\n",
    "    import numpy as np\n",
    "    os.chdir(f'{conf.jobname}/mutations')\n",
    "    def nice_order(aa_l):\n",
    "        nice_order_for_heatmap  = [\"G\",\"P\",\"E\",\"D\",\"R\",\"K\",\"H\",\"Q\",\"N\",\"T\",\"S\",\"Y\",\"W\",\"F\",\"M\",\"C\",\"I\",\"L\",\"V\",\"A\"]\n",
    "        aa_list_for_an = nice_order_for_heatmap.copy()\n",
    "        for item in nice_order_for_heatmap:\n",
    "            if item not in aa_l:\n",
    "                aa_list_for_an.remove(item)\n",
    "        return aa_list_for_an\n",
    "    aa_list = nice_order(aa_list)\n",
    "    ala_scan = {}\n",
    "    ssm = np.zeros([len(aa_list), len(mut)], dtype=float)\n",
    "    pdb_name = conf.cleanaxed_pdb[:-4]\n",
    "\n",
    "    for aa in range(0, len(mut)):\n",
    "        pos = mut[aa]\n",
    "        AA = mut[aa][0]\n",
    "        for i in range(0, len(aa_list)):\n",
    "            amino_acid = aa_list[i]\n",
    "            if AA != amino_acid:\n",
    "                mutation = mut[aa]+amino_acid\n",
    "                n_WT = 0\n",
    "                n_MUT = 0\n",
    "                score_WT = 0\n",
    "                score_MUT = 0\n",
    "                with open(pos+\"/\"+mutation+\"/mutfile.ddg\", 'r') as mutfile:\n",
    "                    for line in mutfile:\n",
    "                        if \"WT\" in line:\n",
    "                            score = float(line.split()[3])\n",
    "                            n_WT += 1\n",
    "                            score_WT += score\n",
    "                        elif \"MUT_\" in line:\n",
    "                            score = float(line.split()[3])\n",
    "                            n_MUT += 1\n",
    "                            score_MUT += score\n",
    "                score_WT = score_WT/n_WT\n",
    "                score_MUT = score_MUT/n_MUT\n",
    "                ddG = score_MUT - score_WT\n",
    "                ssm[i,aa] = float(ddG)\n",
    "\n",
    "\n",
    "    np.savetxt(f\"../../{conf.jobname}_SSM_ddg.csv\", ssm, delimiter=\",\")\n",
    "    os.chdir('../../')\n",
    "    return 0\n",
    "analyze_ssm(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626cb3d6",
   "metadata": {},
   "source": [
    "Once the *SSM_ddg.csv* file is obtained, we can finally plot heatmap and detect which mutation and where could stabilize the protein."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2e392e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualizing Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ed3beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "\n",
    "def plot_heatmap(conf):\n",
    "    conf.back()\n",
    "    def nice_order(aa_l):\n",
    "        nice_order_for_heatmap  = [\"G\",\"P\",\"E\",\"D\",\"R\",\"K\",\"H\",\"Q\",\"N\",\"T\",\"S\",\"Y\",\"W\",\"F\",\"M\",\"C\",\"I\",\"L\",\"V\",\"A\"]\n",
    "        aa_list_for_an = nice_order_for_heatmap.copy()\n",
    "        for item in nice_order_for_heatmap:\n",
    "            if item not in aa_l:\n",
    "                aa_list_for_an.remove(item)\n",
    "        return aa_list_for_an\n",
    "    aa_list = nice_order(conf.aa_list)\n",
    "    mut = conf.mut\n",
    "    df_ddg = pd.read_csv(f'{conf.jobname}_SSM_ddg.csv', header=None)    \n",
    "    rows = {i:aa_list[i] for i in range(len(aa_list))}\n",
    "    columns = {i:mut[i] for i in range(len(mut))}\n",
    "    \n",
    "    df_ddg = df_ddg.rename(columns=columns)\n",
    "    df_ddg = df_ddg.rename(index=rows)\n",
    "    minc = df_ddg.min().min()\n",
    "    range_color = [minc, (-1.5) * minc]\n",
    "    sns.set (rc = {'figure.figsize':(15, 10)})\n",
    "    ax = sns.heatmap(df_ddg,  cmap=\"jet\", annot=True, fmt=\".1f\",linewidth=.5, vmin = minc, vmax = (-1.5) * minc, \\\n",
    "                     cbar_kws={'label': 'ΔΔG', 'orientation': 'vertical'})#, annot_kws={\"size\": 20}\n",
    "    ax.set(xlabel=\"Mutations\", ylabel=\"Amino Acid\")\n",
    "    ax.xaxis.tick_top()\n",
    "%matplotlib inline\n",
    "plot_heatmap(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b1a365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a858cf9",
   "metadata": {},
   "source": [
    "## Exercise 2. \n",
    "PDB 2WH6\n",
    "\n",
    "\n",
    "The positions to mutate: Leu  at 169, Ile at 172, Phe at 176\n",
    "\n",
    "Candidates for investigation: A, I, L, M, F, H, V\n",
    "\n",
    "__Hint__: you have to create a separate _utils_ Python file with all previously used functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4913c39c",
   "metadata": {},
   "source": [
    "the $\\Delta\\Delta G$ will be calculated as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\Large{\\Delta}{\\Delta}G_{interface}={\\frac {\\sum_{i}^{} COMPLEX\\_score_{i} \\\\}{ddg\\_iterations} }-{\\frac {\\sum_{i}^{} SEPARATE\\_score_{i} \\\\}{ddg\\_iterations} }\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cefd37a",
   "metadata": {},
   "source": [
    "Download the structure by command: wget https://files.rcsb.org/download/2WH6.pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267243b8-2d84-486a-99bf-83f1f91a057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution:\n",
    "!wget https://files.rcsb.org/download/2WH6.pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "344b464d-18f0-4780-b3e3-0a25287fc27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "class configs(object):\n",
    "  def __init__(self):\n",
    "\n",
    "    self.PDB_filename = '2WH6.pdb'\n",
    "    self.mut = ['L169', 'I172', 'F176']\n",
    "    self.aa_list = ['A', 'I', 'L']#,'M', 'F', 'H', 'V']\n",
    "    self.jobname = 'full_2WH6'\n",
    "    \n",
    "    self.num_threads = 0\n",
    "    self.ntraj = 2 #20\n",
    "    self.nstruct = 1 #2\n",
    "    self.relax_scorefxn = 'ref2015_cart'\n",
    "    self.ddg_iterations = 3\n",
    "    self.force_iterations = False\n",
    "    self.ddg_score_cutoff = 1.0\n",
    "    self.ddg_dump_pdbs = True\n",
    "    self.ddg_bbnbrs = 1\n",
    "    self.fa_max_dis = 9.0\n",
    "    self.ddg_scorefxn = 'ref2015_cart'\n",
    "    \n",
    "    import os\n",
    "    if not os.path.exists(self.PDB_filename):\n",
    "        raise Exception(f\"Sorry, the file with name {self.PDB_filename[:-4]} was not found.\")\n",
    "    \n",
    "    if self.num_threads == 0:\n",
    "        import os \n",
    "        nslots = int(os.environ['SLURM_CPUS_PER_TASK'])\n",
    "        self.num_threads = nslots\n",
    "    self.coord_cst = True\n",
    "    py_flags = \"-ddg:mut_file mutfile -ddg:iterations \"\n",
    "    py_flags += str(self.ddg_iterations) \n",
    "    py_flags += \" -force_iterations \"\n",
    "    py_flags += str(self.force_iterations).lower()\n",
    "    py_flags += \" -ddg::score_cutoff \"\n",
    "    py_flags += str(self.ddg_score_cutoff)\n",
    "    py_flags += \" -ddg::cartesian -ddg::dump_pdbs \"\n",
    "    py_flags += str(self.ddg_dump_pdbs).lower()\n",
    "    py_flags += \" -ddg:bbnbrs \"\n",
    "    py_flags += str(self.ddg_bbnbrs)\n",
    "    py_flags += \" -fa_max_dis \"\n",
    "    py_flags += str(self.fa_max_dis)\n",
    "    py_flags += \" -score:weights \"\n",
    "    py_flags += str(self.ddg_scorefxn)\n",
    "    py_flags += \".wts\"\n",
    "    self.py_flags = py_flags\n",
    "    import os\n",
    "    self.working_dir = os.getcwd()\n",
    "  def back(self):\n",
    "        import os\n",
    "        os.chdir(self.working_dir)\n",
    "\n",
    "conf = configs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d08020",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exercise 2.1.  Computing heatmap for whole protein\n",
    "from utils import *\n",
    "\n",
    "class configs(object):\n",
    "  def __init__(self):\n",
    "\n",
    "    self.PDB_filename = '2WH6.pdb'\n",
    "    self.mut = ['L169', 'I172', 'F176']\n",
    "    self.aa_list = ['A', 'I', 'L']#,'M', 'F', 'H', 'V']\n",
    "    self.jobname = 'full_2WH6'\n",
    "    \n",
    "    self.num_threads = 0\n",
    "    self.ntraj = 2 #20\n",
    "    self.nstruct = 1 #2\n",
    "    self.relax_scorefxn = 'ref2015_cart'\n",
    "    self.ddg_iterations = 3\n",
    "    self.force_iterations = False\n",
    "    self.ddg_score_cutoff = 1.0\n",
    "    self.ddg_dump_pdbs = True\n",
    "    self.ddg_bbnbrs = 1\n",
    "    self.fa_max_dis = 9.0\n",
    "    self.ddg_scorefxn = 'ref2015_cart'\n",
    "    \n",
    "    import os\n",
    "    if not os.path.exists(self.PDB_filename):\n",
    "        raise Exception(f\"Sorry, the file with name {self.PDB_filename[:-4]} was not found.\")\n",
    "    \n",
    "    if self.num_threads == 0:\n",
    "        import os \n",
    "        nslots = int(os.environ['SLURM_CPUS_PER_TASK'])\n",
    "        self.num_threads = nslots\n",
    "    self.coord_cst = True\n",
    "    py_flags = \"-ddg:mut_file mutfile -ddg:iterations \"\n",
    "    py_flags += str(self.ddg_iterations) \n",
    "    py_flags += \" -force_iterations \"\n",
    "    py_flags += str(self.force_iterations).lower()\n",
    "    py_flags += \" -ddg::score_cutoff \"\n",
    "    py_flags += str(self.ddg_score_cutoff)\n",
    "    py_flags += \" -ddg::cartesian -ddg::dump_pdbs \"\n",
    "    py_flags += str(self.ddg_dump_pdbs).lower()\n",
    "    py_flags += \" -ddg:bbnbrs \"\n",
    "    py_flags += str(self.ddg_bbnbrs)\n",
    "    py_flags += \" -fa_max_dis \"\n",
    "    py_flags += str(self.fa_max_dis)\n",
    "    py_flags += \" -score:weights \"\n",
    "    py_flags += str(self.ddg_scorefxn)\n",
    "    py_flags += \".wts\"\n",
    "    self.py_flags = py_flags\n",
    "    import os\n",
    "    self.working_dir = os.getcwd()\n",
    "  def back(self):\n",
    "        import os\n",
    "        os.chdir(self.working_dir)\n",
    "\n",
    "conf = configs()\n",
    "\n",
    "preparation(conf)\n",
    "run_relax_job_parallel(conf)\n",
    "conf.cleanaxed_pdb, _ = get_scores(conf)\n",
    "mutfiles_preparation(conf)\n",
    "run_ddg_calc_parallel(conf)\n",
    "analyze_ssm(conf)\n",
    "%matplotlib inline\n",
    "plot_heatmap(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4603be",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Excercise 2.2. Extract chain B from PDB file.\n",
    "\n",
    "#Solution:\n",
    "from Bio.PDB import PDBParser, PDBIO\n",
    "io = PDBIO()\n",
    "pdb = PDBParser().get_structure(\"2WH6\", \"2WH6.pdb\")\n",
    "for chain in pdb.get_chains():\n",
    "    if chain.get_id() == 'B':\n",
    "        io.set_structure (chain)\n",
    "        io.save(pdb.get_id() + \"_\" + chain.get_id() + \".pdb\")\n",
    "\n",
    "\n",
    "io = PDBIO()\n",
    "pdb = PDBParser().get_structure(\"2WH6\", \"2WH6.pdb\")\n",
    "for chain in pdb.get_chains():\n",
    "    if chain.get_id() == 'A':\n",
    "        io.set_structure (chain)\n",
    "        io.save(pdb.get_id() + \"_\" + chain.get_id() + \".pdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c284fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Excercise 2.2.1 Visualize Chains with different colours of chains 159, 1 ,  51\n",
    "import py3Dmol\n",
    "view=py3Dmol.view()\n",
    "view.addModel(open('2WH6_A.pdb', 'r').read(),'pdb')\n",
    "view.addModel(open('2WH6_B.pdb', 'r').read(),'pdb')\n",
    "view.zoomTo()\n",
    "view.setBackgroundColor('white')\n",
    "view.setStyle({'chain':'A'},{'cartoon': {'color':'skyblue'}})\n",
    "view.setStyle({'chain':'B'},{'cartoon': {'color':'yellow'}})\n",
    "#view.addStyle({'chain':'B'},{'stick':{'color':'skyblue'}})\n",
    "#view.setStyle({'chain':'B'},{'cartoon': {'color':'yellow'},'stick': {'color':'skyblue'} })\n",
    "view.addStyle({'chain':'B','resi':50 + 12},{'stick':{'color':'red'}})\n",
    "view.addStyle({'chain':'B','resi':50 + 15},{'stick':{'color':'red'}})\n",
    "view.addStyle({'chain':'B','resi':50 + 19},{'stick':{'color':'red'}})\n",
    "view.addLabel(\"L169\",{'fontOpacity':1},{'chain':'B','resi':50 + 12})\n",
    "view.addLabel(\"I172\",{'fontOpacity':1},{'chain':'B','resi':50 + 15})\n",
    "view.addLabel(\"F176\",{'fontOpacity':1},{'chain':'B','resi':50 + 19})\n",
    "view.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929f0147",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Excercise 2.2.2 The same with surfaces\n",
    "import py3Dmol\n",
    "view=py3Dmol.view()\n",
    "view.addModel(open('2WH6_A.pdb', 'r').read(),'pdb')\n",
    "view.addModel(open('2WH6_B.pdb', 'r').read(),'pdb')\n",
    "view.zoomTo()\n",
    "view.setBackgroundColor('white')\n",
    "view.setStyle({'chain':'A'},{'cartoon': {'color':'skyblue'}})\n",
    "view.setStyle({'chain':'B'},{'cartoon': {'color':'yellow'} })\n",
    "\n",
    "view.addStyle({'chain':'B','resi':50 + 12},{'stick':{'color':'red'}})\n",
    "view.addStyle({'chain':'B','resi':50 + 15},{'stick':{'color':'red'}})\n",
    "view.addStyle({'chain':'B','resi':50 + 19},{'stick':{'color':'red'}})\n",
    "\n",
    "view.addSurface(py3Dmol.VDW,{'opacity':0.7,'color':'white'}, {'chain':'A'})\n",
    "#view.addSurface(py3Dmol.VDW,{'opacity':0.7,'color':'purpleCarbon'}, {'chain':'B'})\n",
    "view.addLabel(\"L169\",{'fontOpacity':1},{'chain':'B','resi':50 + 12})\n",
    "view.addLabel(\"I172\",{'fontOpacity':1},{'chain':'B','resi':50 + 15})\n",
    "view.addLabel(\"F176\",{'fontOpacity':1},{'chain':'B','resi':50 + 19})\n",
    "view.show() #Leu at 169, Ile at 172, Phe at 176"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c459d89-3891-4981-92e1-3200ea7f603b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Excercise 2.3. Computing heatmap for chain B of 2WH6 protein\n",
    "\n",
    "from utils import *\n",
    "\n",
    "class configs(object):\n",
    "  def __init__(self):\n",
    "\n",
    "    self.PDB_filename = '2WH6_B.pdb'\n",
    "    self.mut = ['L12', 'I15', 'F19']\n",
    "    self.aa_list = ['A', 'I', 'L']#,'M', 'F', 'H', 'V']\n",
    "    self.jobname = 'chB_2WH6_2'\n",
    "    \n",
    "    self.num_threads = 0\n",
    "    self.ntraj = 2# 20\n",
    "    self.nstruct = 1# 2\n",
    "    self.relax_scorefxn = 'ref2015_cart'\n",
    "    self.ddg_iterations = 3\n",
    "    self.force_iterations = False\n",
    "    self.ddg_score_cutoff = 1.0\n",
    "    self.ddg_dump_pdbs = True\n",
    "    self.ddg_bbnbrs = 1\n",
    "    self.fa_max_dis = 9.0\n",
    "    self.ddg_scorefxn = 'ref2015_cart'\n",
    "    \n",
    "    import os\n",
    "    if not os.path.exists(self.PDB_filename):\n",
    "        raise Exception(f\"Sorry, the file with name {self.PDB_filename[:-4]} was not found.\")\n",
    "    \n",
    "    if self.num_threads == 0:\n",
    "        import os \n",
    "        nslots = int(os.environ['SLURM_CPUS_PER_TASK'])\n",
    "        self.num_threads = nslots\n",
    "    self.coord_cst = True\n",
    "    py_flags = \"-ddg:mut_file mutfile -ddg:iterations \"\n",
    "    py_flags += str(self.ddg_iterations) \n",
    "    py_flags += \" -force_iterations \"\n",
    "    py_flags += str(self.force_iterations).lower()\n",
    "    py_flags += \" -ddg::score_cutoff \"\n",
    "    py_flags += str(self.ddg_score_cutoff)\n",
    "    py_flags += \" -ddg::cartesian -ddg::dump_pdbs \"\n",
    "    py_flags += str(self.ddg_dump_pdbs).lower()\n",
    "    py_flags += \" -ddg:bbnbrs \"\n",
    "    py_flags += str(self.ddg_bbnbrs)\n",
    "    py_flags += \" -fa_max_dis \"\n",
    "    py_flags += str(self.fa_max_dis)\n",
    "    py_flags += \" -score:weights \"\n",
    "    py_flags += str(self.ddg_scorefxn)\n",
    "    py_flags += \".wts\"\n",
    "    self.py_flags = py_flags\n",
    "    import os\n",
    "    self.working_dir = os.getcwd()\n",
    "  def back(self):\n",
    "        import os\n",
    "        os.chdir(self.working_dir)\n",
    "\n",
    "conf_chB = configs()\n",
    "\n",
    "preparation(conf_chB)\n",
    "run_relax_job_parallel(conf_chB)\n",
    "conf_chB.cleanaxed_pdb, _ = get_scores(conf_chB)\n",
    "mutfiles_preparation(conf_chB)\n",
    "run_ddg_calc_parallel(conf_chB)\n",
    "analyze_ssm(conf_chB)\n",
    "%matplotlib inline\n",
    "plot_heatmap(conf_chB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d00b64-f02c-4eda-a6c1-12b37ed3076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Excercise 2.4. Final single-point mutations heatmap for protein-protein interface interaction.\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "def nice_order(aa_l):\n",
    "        nice_order_for_heatmap  = [\"G\",\"P\",\"E\",\"D\",\"R\",\"K\",\"H\",\"Q\",\"N\",\"T\",\"S\",\"Y\",\"W\",\"F\",\"M\",\"C\",\"I\",\"L\",\"V\",\"A\"]\n",
    "        aa_list_for_an = nice_order_for_heatmap.copy()\n",
    "        for item in nice_order_for_heatmap:\n",
    "            if item not in aa_l:\n",
    "                aa_list_for_an.remove(item)\n",
    "        return aa_list_for_an\n",
    "\n",
    "heatmap_2WH6 = pd.read_csv(f'{conf.jobname}_SSM_ddg.csv', header=None)    \n",
    "\n",
    "heatmap_2WH6_B = pd.read_csv(f'{conf_chB.jobname}_SSM_ddg.csv', header=None)  \n",
    "\n",
    "df_ddg = heatmap_2WH6 - heatmap_2WH6_B\n",
    "aa_list = nice_order(conf.aa_list)\n",
    "mut = conf.mut\n",
    "rows = {i:aa_list[i] for i in range(len(aa_list))}\n",
    "columns = {i:mut[i] for i in range(len(mut))}\n",
    "    \n",
    "df_ddg = df_ddg.rename(columns=columns)\n",
    "df_ddg = df_ddg.rename(index=rows)\n",
    "minc = df_ddg.min().min()\n",
    "range_color = [minc, (-1.5) * minc]\n",
    "sns.set (rc = {'figure.figsize':(15, 10)})\n",
    "ax = sns.heatmap(df_ddg,  cmap=\"jet\", annot=True, fmt=\".1f\",linewidth=.5, vmin = minc, vmax = (-1.5) * minc, \\\n",
    "                     cbar_kws={'label': 'ΔΔG', 'orientation': 'vertical'})#, annot_kws={\"size\": 20}\n",
    "ax.set(xlabel=\"Mutations\", ylabel=\"Amino Acid\")\n",
    "ax.xaxis.tick_top()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8e1fef",
   "metadata": {},
   "source": [
    "## FastDesign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8696afe-64f6-401f-9f03-e184e1227395",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations = [] #List of positions (INTEGER) that can mutate\n",
    "path = \"mutations.resfile\"\n",
    "\n",
    "def write_resfile(mutations,path):\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(\"NATAA\\n\")\n",
    "        f.write(\"start\\n\\n\")\n",
    "        for m in mutations:\n",
    "            f.write(\"%s A NOTAA C\\n\" %(str(m)))\n",
    "    return 0\n",
    "write_resfile(mutations, path)\n",
    "        \n",
    "def design_job(args):\n",
    "    name_clean, nstruct, scorefxn_name, dest = args\n",
    "    import os\n",
    "    import logging\n",
    "    current_dir = os.getcwd()\n",
    "    os.chdir(dest)\n",
    "    logging.basicConfig(filename='stdout.txt', level=logging.INFO)\n",
    "    \n",
    "    import pyrosetta\n",
    "    pyrosetta.init()\n",
    "    pose = pyrosetta.pose_from_pdb(name_clean)\n",
    "    scorefxn = pyrosetta.create_score_function(scorefxn_name)\n",
    "    print(pose)\n",
    "    print(args)\n",
    "    xml = pyrosetta.rosetta.protocols.rosetta_scripts.XmlObjects.create_from_string(\"\"\"\n",
    "    <ROSETTASCRIPTS>\n",
    "        <SCOREFXNS>\n",
    "            <ScoreFunction name=\"SFX1\" weights=\"ref2015\">\n",
    "        </ScoreFunction>\n",
    "        </SCOREFXNS>\n",
    "        <RESIDUE_SELECTORS>\n",
    "        </RESIDUE_SELECTORS>\n",
    "        <TASKOPERATIONS>\n",
    "            <ReadResfile name=\"resfile\" filename=\"mutations.resfile\" />\n",
    "        </TASKOPERATIONS>\n",
    "        <FILTERS>\n",
    "        </FILTERS>\n",
    "        <MOVERS>\n",
    "           <FastDesign name=\"fdesign\" task_operations=\"resfile\" scorefxn=\"SFX1\" />\n",
    "        </MOVERS>\n",
    "        <APPLY_TO_POSE/>\n",
    "        <PROTOCOLS>\n",
    "           <Add mover=\"fdesign\" />\n",
    "        </PROTOCOLS>\n",
    "    </ROSETTASCRIPTS>\n",
    "    \"\"\").get_mover(\"ParsedProtocol\")\n",
    "    \n",
    "    working_dir = os.getcwd()\n",
    "    output_dir = dest\n",
    "    jd = pyrosetta.toolbox.py_jobdistributor.PyJobDistributor(pdb_name=name_clean[:-4], nstruct=nstruct, scorefxn=scorefxn)\n",
    "    jd.native_pose = pose\n",
    "    while not jd.job_complete:\n",
    "        test_pose = pose.clone()\n",
    "        xml.apply(test_pose)\n",
    "        jd.output_decoy(test_pose)\n",
    "    os.chdir(current_dir)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bc60fc-e76d-4b48-b2d5-df7e860896a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = PDB_CLEAN_PDB, 5, 'ref2015_cart', TMP_FOLDER\n",
    "design_job(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed721bde-17b8-44ef-ba8a-43a50971a2f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b8dc44-fb7b-44d6-81f8-fdd52d74f746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ad89f8-f482-4e26-b100-5e9b074762b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd357e7-ae6c-4a02-b8c8-b9f2ef84bae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f2a225-5c97-4ea3-9fc9-cc3ffe262482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737aa586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import argparse\n",
    "import pyrosetta\n",
    "\n",
    "def Fast_Design_RUN(target=None, filename=None, run_num=None):\n",
    "    # Initialize PyRosetta with custom flags\n",
    "    pyrosetta.init('''\n",
    "        -relax:default_repeats 5\n",
    "        -relax:constrain_relax_to_start_coords\n",
    "        -relax:coord_constrain_sidechains\n",
    "        -relax:ramp_constraints false\n",
    "        -score::hbond_params correct_params\n",
    "        -no_his_his_pairE\n",
    "        -extrachi_cutoff 1\n",
    "        -multi_cool_annealer 10\n",
    "        -ex1 -ex2\n",
    "        -use_input_sc\n",
    "        -flip_HNQ\n",
    "        -ignore_unrecognized_res\n",
    "        -relax:coord_cst_stdev 0.5\n",
    "    ''')\n",
    "\n",
    "    # Clean pdb\n",
    "    pyrosetta.toolbox.cleaning.cleanATOM(filename)\n",
    "    # Load the cleaned PDB\n",
    "    base = os.path.splitext(filename)[0]\n",
    "    btl = pyrosetta.pose_from_pdb(f\"{base}.clean.pdb\")\n",
    "    original_pose = btl.clone()\n",
    "    scorefxn = pyrosetta.get_fa_scorefxn()\n",
    "    print(\"Original score: \", scorefxn.score(btl))\n",
    "\n",
    "    # Setup directory structure\n",
    "    main_dir = os.getcwd()\n",
    "    output_dir = os.path.join(\"Outputs\", f\"mutating_res{target}\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    os.chdir(output_dir)\n",
    "\n",
    "    # FastRelax \n",
    "    fr = pyrosetta.rosetta.protocols.relax.FastRelax()\n",
    "    fr.set_scorefxn(scorefxn)\n",
    "    fr.apply(btl)\n",
    "    print(\"Relaxed score: \", scorefxn.score(btl))\n",
    "    relaxed_pose = btl.clone()\n",
    "    btl.dump_pdb(f\"relaxed_{run_num}_{filename}\")\n",
    "\n",
    "    # Job distributor for designs\n",
    "    job = pyrosetta.toolbox.py_jobdistributor.PyJobDistributor(f'{base}_design_{run_num}', 8, scorefxn)\n",
    "    job.native_pose = original_pose\n",
    "    pose = pyrosetta.Pose()\n",
    "\n",
    "    while not job.job_complete:\n",
    "        pose.assign(relaxed_pose)\n",
    "        fastdesign(pose, target)# design\n",
    "        i = print_mutations(original_pose, pose, job.current_name) #prints the mutations\n",
    "        if len(i) == 0:\n",
    "            continue\n",
    "        fr.apply(pose) # relax\n",
    "        print(\"FinalScore: \", scorefxn.score(pose))\n",
    "        job.output_decoy(pose)\n",
    "\n",
    "    os.chdir(main_dir)\n",
    "\n",
    "    \n",
    "def fastdesign(pose, target):\n",
    "    \"\"\"Setups the design around protocol and design the pose accordingly.\"\"\"\n",
    "    scorefxn = pyrosetta.get_fa_scorefxn()\n",
    "    #Selectors\n",
    "    target_residue = pyrosetta.rosetta.core.select.residue_selector.ResidueIndexSelector(str(target))\n",
    "    design_radius = random.randint(8, 12)\n",
    "    design_shell = pyrosetta.rosetta.core.select.residue_selector.NeighborhoodResidueSelector(target_residue, design_radius, False)\n",
    "    repack_shell = pyrosetta.rosetta.core.select.residue_selector.NeighborhoodResidueSelector(target_residue, design_radius + 4, True)\n",
    "    # Important residues that should not be designed\n",
    "    imp_residues = \"2,7,8,9,10,11,12,13,14,15,16,17,18\"#,19,20,37,42,45,48,51,82,97,105,107,120,141,142,149,158,194,201,209,218,226,230,235\"\n",
    "    imp_residue_selector = pyrosetta.rosetta.core.select.residue_selector.ResidueIndexSelector(imp_residues)\n",
    "\n",
    "    # Setup TaskFactory\n",
    "    tf = pyrosetta.rosetta.core.pack.task.TaskFactory()\n",
    "    # Task operations\n",
    "    tf.push_back(pyrosetta.rosetta.core.pack.task.operation.InitializeFromCommandline())\n",
    "    tf.push_back(pyrosetta.rosetta.core.pack.task.operation.IncludeCurrent())\n",
    "    tf.push_back(pyrosetta.rosetta.core.pack.task.operation.NoRepackDisulfides())\n",
    "    tf.push_back(pyrosetta.rosetta.core.pack.task.operation.OperateOnResidueSubset(\n",
    "        pyrosetta.rosetta.core.pack.task.operation.RestrictToRepackingRLT(), imp_residue_selector, False))\n",
    "    tf.push_back(pyrosetta.rosetta.core.pack.task.operation.OperateOnResidueSubset(\n",
    "        pyrosetta.rosetta.core.pack.task.operation.RestrictToRepackingRLT(), design_shell, True))\n",
    "    tf.push_back(pyrosetta.rosetta.core.pack.task.operation.OperateOnResidueSubset(\n",
    "        pyrosetta.rosetta.core.pack.task.operation.PreventRepackingRLT(), repack_shell, True))\n",
    "    \n",
    "    # Setup MoveMap for fixed backbone\n",
    "    mm = pyrosetta.rosetta.core.kinematics.MoveMap()\n",
    "    mm.set_bb(False)\n",
    "    mm.set_chi(True)\n",
    "    mm.set_jump(True)\n",
    "        \n",
    "    # # Setup MoveMap for flexible backbone\n",
    "    # mm = pyrosetta.rosetta.core.kinematics.MoveMap()\n",
    "    # mm.set_bb(True)\n",
    "    # mm.set_chi(True)\n",
    "    # mm.set_jump(True)\n",
    "\n",
    "    # Mover Setup\n",
    "    fd = pyrosetta.rosetta.protocols.denovo_design.movers.FastDesign(scorefxn_in=scorefxn, script_file=\"MonomerDesign2019\")\n",
    "    fd.set_task_factory(tf)\n",
    "    fd.set_movemap(mm)\n",
    "    fd.set_scorefxn(scorefxn)\n",
    "    fd.apply(pose)    \n",
    "    print(\"Design: \", scorefxn.score(pose))\n",
    "    print_radius(design_radius)\n",
    "\n",
    "def print_mutations(original_pose, designed_pose, job_name):\n",
    "    \"\"\"Prints and logs the mutations between the original and designed poses.\"\"\"\n",
    "    original_seq = original_pose.sequence()\n",
    "    designed_seq = designed_pose.sequence()\n",
    "    mutations = []\n",
    "    for i in range(0, original_pose.total_residue()):\n",
    "        if original_seq[i] != designed_seq[i]:\n",
    "            resid = original_pose.pdb_info().pose2pdb(i+1)\n",
    "            mutations.append(f\"{original_seq[i]}{resid.split()[0]}{designed_seq[i]}\")\n",
    "            # mutations.append(f\"{original_seq[i]}{i+1}{designed_seq[i]}\")\n",
    "    mutations_str = f\"{job_name} - Mutations: \" + \", \".join(mutations)\n",
    "    print(mutations_str)\n",
    "    with open(\"mutations.txt\", \"a\") as mutation_file:\n",
    "        if not len(mutations) == 0:\n",
    "            mutation_file.write(mutations_str + \"\\n\")\n",
    "        else:\n",
    "            mutation_file.write(\"\\n\")\n",
    "        mutation_file.close()\n",
    "    return mutations\n",
    "\n",
    "def print_radius(radius):\n",
    "    \"\"\"Prints and logs the radius of design shell and repack shell.\"\"\"\n",
    "    radius_str = f\"Design shell: {radius}A      Repack shell: {radius+4}A\"\n",
    "    print(radius_str)\n",
    "    with open(\"radius.txt\", \"a\") as radius_file:\n",
    "        radius_file.write(radius_str + \"\\n\")\n",
    "        radius_file.close()            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86484a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fast_Design_RUN(target= INTEGER NUM of RES, filename=STR FILENAME of PDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ae60a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9b71e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27a009d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2358a9cf-20e7-4ce2-ade6-3471a15fda5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81f7811-15c3-4cab-85c9-3e960deb2fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8dc7eb11",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tiny benchmark (bonus)\n",
    "Let's go through tiny benchmark and compare Pyrosetta cleaning function with bash __grep__ funciton, and custom script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58d8fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import datetime\n",
    "from multiprocessing import Process\n",
    "n_repeats = 200\n",
    "\n",
    "class configs(object):\n",
    "  def __init__(self):\n",
    "\n",
    "    self.PDB_filename = '2WH6.pdb'\n",
    "    self.mut = ['L169', 'I172', 'F176']\n",
    "    self.aa_list = ['A', 'I', 'L']#,'M', 'F', 'H', 'V']\n",
    "    self.jobname = 'full_2WH6'\n",
    "    \n",
    "    self.num_threads = 0\n",
    "    self.ntraj = 2 #20\n",
    "    self.nstruct = 1 #2\n",
    "    self.relax_scorefxn = 'ref2015_cart'\n",
    "    self.ddg_iterations = 3\n",
    "    self.force_iterations = False\n",
    "    self.ddg_score_cutoff = 1.0\n",
    "    self.ddg_dump_pdbs = True\n",
    "    self.ddg_bbnbrs = 1\n",
    "    self.fa_max_dis = 9.0\n",
    "    self.ddg_scorefxn = 'ref2015_cart'\n",
    "    \n",
    "    import os\n",
    "    if not os.path.exists(self.PDB_filename):\n",
    "        raise Exception(f\"Sorry, the file with name {self.PDB_filename[:-4]} was not found.\")\n",
    "    \n",
    "    if self.num_threads == 0:\n",
    "        import os \n",
    "        nslots = int(os.environ['SLURM_CPUS_PER_TASK'])\n",
    "        self.num_threads = nslots\n",
    "    self.coord_cst = True\n",
    "    py_flags = \"-ddg:mut_file mutfile -ddg:iterations \"\n",
    "    py_flags += str(self.ddg_iterations) \n",
    "    py_flags += \" -force_iterations \"\n",
    "    py_flags += str(self.force_iterations).lower()\n",
    "    py_flags += \" -ddg::score_cutoff \"\n",
    "    py_flags += str(self.ddg_score_cutoff)\n",
    "    py_flags += \" -ddg::cartesian -ddg::dump_pdbs \"\n",
    "    py_flags += str(self.ddg_dump_pdbs).lower()\n",
    "    py_flags += \" -ddg:bbnbrs \"\n",
    "    py_flags += str(self.ddg_bbnbrs)\n",
    "    py_flags += \" -fa_max_dis \"\n",
    "    py_flags += str(self.fa_max_dis)\n",
    "    py_flags += \" -score:weights \"\n",
    "    py_flags += str(self.ddg_scorefxn)\n",
    "    py_flags += \".wts\"\n",
    "    self.py_flags = py_flags\n",
    "    import os\n",
    "    self.working_dir = os.getcwd()\n",
    "  def back(self):\n",
    "        import os\n",
    "        os.chdir(self.working_dir)\n",
    "\n",
    "conf = configs()\n",
    "\n",
    "\n",
    "if not os.path.exists('small_benchmark'):\n",
    "    os.mkdir('small_benchmark')\n",
    "if not os.path.exists(f'small_benchmark/{conf.PDB_filename}'):\n",
    "    os.system(f'cp {conf.PDB_filename} ./small_benchmark/{conf.PDB_filename}')\n",
    "    \n",
    "def pyrosetta_cleaning():\n",
    "    import logging\n",
    "    logging.basicConfig(filename='small_benchmark/stdout.txt', level=logging.INFO)\n",
    "    import pyrosetta\n",
    "    pyrosetta.init(\"-mute all\")\n",
    "    start = time.time()\n",
    "    for i in range(n_repeats):\n",
    "        pose = pyrosetta.pose_from_pdb(f\"small_benchmark/{conf.PDB_filename}\")\n",
    "        pyrosetta.toolbox.cleanATOM(f\"small_benchmark/{conf.PDB_filename}\")\n",
    "    end = time.time()\n",
    "    import os\n",
    "    duration_pyrosetta = str(end - start)\n",
    "    os.system(f'echo {duration_pyrosetta} > small_benchmark/pyrosetta_cleaning.txt')\n",
    "\n",
    "def grep_cleaning():\n",
    "    start = time.time()\n",
    "    for i in range(n_repeats):\n",
    "        os.system(f'''grep \"^ATOM\" small_benchmark/{conf.PDB_filename} > small_benchmark/{conf.PDB_filename[:-4]}_clean.pdb''')\n",
    "    end = time.time()\n",
    "    return end - start\n",
    "\n",
    "def custom_cleaning():\n",
    "    \n",
    "    start = time.time()\n",
    "    for i in range(n_repeats):\n",
    "        from script.clean_pdb import main as clean_pdb\n",
    "        clean_pdb(f'small_benchmark/{conf.PDB_filename}', True)\n",
    "        \n",
    "    end = time.time()\n",
    "    return end - start\n",
    "\n",
    "\n",
    "Proc = Process(target=pyrosetta_cleaning)\n",
    "Proc.start()\n",
    "Proc.join()\n",
    "\n",
    "duration_pyrosetta = float(open('small_benchmark/pyrosetta_cleaning.txt','r').readline())\n",
    "duration_grep = grep_cleaning()\n",
    "duration_custom = custom_cleaning()\n",
    "\n",
    "print(\"\\n\")\n",
    "print('PyRosetta cleaning for ' + str(n_repeats) + \\\n",
    "      ' repeats: ' + \"{:.2f}\".format(round(duration_pyrosetta, 2)) + \" seconds.\")\n",
    "print('bash grep cleaning for ' + str(n_repeats) + \\\n",
    "      ' repeats: ' +\"{:.2f}\".format(round(duration_grep, 2)) + \" seconds.\")\n",
    "print('Custom cleaning for ' + str(n_repeats) + \\\n",
    "      ' repeats: ' +\"{:.2f}\".format(round(duration_custom, 2)) + \" seconds.\")\n",
    "print(\"\\n\\t\" + \"Speed up = \" + str(duration_pyrosetta / duration_grep) + \" times. grep over PyRosetta\")\n",
    "print(\"\\n\\t\" + \"Speed up = \" + str(duration_pyrosetta / duration_custom) + \" times. Custom over PyRosetta\")\n",
    "Proc.kill()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c254239-eec3-4f1f-9885-1f9210135cef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
