{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f80da1ab-98f4-4b87-a508-0017e9cc6ce1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Predicting the ∆∆G of single point mutations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f344906f-055b-494e-85cb-0208023e1dfe",
   "metadata": {},
   "source": [
    "## The Heatmap, or Respect and Audience Again.\n",
    "<center><img src=\"img/Slide.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4d693c-1491-4ee0-9670-a739939d1f0f",
   "metadata": {},
   "source": [
    "## Introduction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c45433d-c1c1-481d-be27-853c15fdf79e",
   "metadata": {},
   "source": [
    "<center><img src=\"img/img1.jpeg\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d5be78-ba52-4161-877c-3f54fb057bc9",
   "metadata": {},
   "source": [
    "Accurately estimating the thermodynamic cost of a mutation is a building block of protein engineering and design. We will take a small protein and try to make it better. Or at least more stable. In order to achieve that, we are going to carry out \"alchemical\" mutations during the simulations and compute the corresponding free energy changes. If we do this both in the folded and unfolded states, and compute the difference between them, this will yield us an estimate of the difference in stability between wild type and mutant, as indicated in this thermodynamic cyclle:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5244d620-3774-4005-8c5f-dda2fc18943e",
   "metadata": {},
   "source": [
    "<center><img src=\"img/cycle.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b38e7f6-c95d-41c5-9d77-a7817670abce",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\Large G=H - TS \\\\\n",
    "\\Large {\\Delta}G_{fold} = (H_{unfold} - H_{fold})-T*(S_{unfold} - S_{fold}) \\\\\n",
    "\\Large {\\Delta}{\\Delta}G = {\\Delta}G_{fold_{MT}} - {\\Delta}G_{fold_{  WT}}\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d7ec24-298a-4a2f-8787-a5552ce35b24",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Objectives\n",
    "1. Setup a parameters\n",
    "2. Prepare files\n",
    "3. Compute the ∆∆G of mutation\n",
    "4. Analyze contributions to the change in stability\n",
    "5. Visualize the model in PyMOL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bec20c8-a4af-4163-a6da-414035eb7c5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup\n",
    "The first step is to initialize __configs__ _class_ and load the protein of interest. \n",
    "\n",
    "Mandatory class attributes:\n",
    "1. __PDB_filename__ - the full (with .pdb extension) protein filename\n",
    "2. __mut__ - a list of investigated mutations in Python format\n",
    "3. __aa_list__ -  a list of tested mutations in each position provided in \"mut\" list\n",
    "4. __jobname__ - a temporary folder which will contains some intermediate results\n",
    "\n",
    "Optional class atributes (already initialized by default and mostly ogten used values):\n",
    "1. __num_threads__ - number of threads, set 0 to maximum available physical cores\n",
    "2. __ntraj__ - the amount of trajectories to structure relaxation before ΔΔG calc\n",
    "3. __nstruct__ - the value of relaxed structures from each trajectory\n",
    "4. __relax_scorefxn__ - supply a different score functon from the Rosetta default\n",
    "5. __ddg_iterations__ - \n",
    "6. __force_iterations__ - if this flag is on the protocol will stop when the results converge on a score\n",
    "7. __ddg_score_cutoff__ - if the lowest energy scores are within this cutoff the protocol will end early\n",
    "8. __ddg_dump_pdbs__ - you can save mutants PDBs if you want\n",
    "9. __ddg_bbnbrs__ - bb dof, suggestion: i-1, i, i+1\n",
    "10. __fa_max_dis__ - modify fa_atr and fa_sol behavior, really important for protein stability\n",
    "11. __ddg_scorefxn__ - supply a different score functon from the Rosetta default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033ae30e-e34c-4f0f-84c8-e3ea1bd04dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class configs(object):\n",
    "  def __init__(self):\n",
    "\n",
    "    self.PDB_filename = 'peptide.pdb'\n",
    "    self.mut = ['L1', 'Y2', 'I3', 'Q4', 'W5', 'L6', 'K7', 'D8']\n",
    "    self.aa_list = ['M', 'F','G', 'A', 'I', 'P', 'S']\n",
    "    self.jobname = 'jobname'\n",
    "    \n",
    "    self.num_threads = 0\n",
    "    self.ntraj = 20\n",
    "    self.nstruct = 2\n",
    "    self.relax_scorefxn = 'ref2015_cart'\n",
    "    self.ddg_iterations = 3\n",
    "    self.force_iterations = False\n",
    "    self.ddg_score_cutoff = 1.0\n",
    "    self.ddg_dump_pdbs = True\n",
    "    self.ddg_bbnbrs = 1\n",
    "    self.fa_max_dis = 9.0\n",
    "    self.ddg_scorefxn = 'ref2015_cart'\n",
    "    \n",
    "    import os\n",
    "    if not os.path.exists(self.PDB_filename):\n",
    "        raise Exception(f\"Sorry, the file with name {self.PDB_filename[:-4]} was not found.\")\n",
    "    \n",
    "    if self.num_threads == 0:\n",
    "        import os \n",
    "        nslots = int(os.environ['SLURM_CPUS_PER_TASK'])\n",
    "        self.num_threads = nslots\n",
    "    self.coord_cst = True\n",
    "    py_flags = \"-ddg:mut_file mutfile -ddg:iterations \"\n",
    "    py_flags += str(self.ddg_iterations) \n",
    "    py_flags += \" -force_iterations \"\n",
    "    py_flags += str(self.force_iterations).lower()\n",
    "    py_flags += \" -ddg::score_cutoff \"\n",
    "    py_flags += str(self.ddg_score_cutoff)\n",
    "    py_flags += \" -ddg::cartesian -ddg::dump_pdbs \"\n",
    "    py_flags += str(self.ddg_dump_pdbs).lower()\n",
    "    py_flags += \" -ddg:bbnbrs \"\n",
    "    py_flags += str(self.ddg_bbnbrs)\n",
    "    py_flags += \" -fa_max_dis \"\n",
    "    py_flags += str(self.fa_max_dis)\n",
    "    py_flags += \" -score:weights \"\n",
    "    py_flags += str(self.ddg_scorefxn)\n",
    "    py_flags += \".wts\"\n",
    "    self.py_flags = py_flags\n",
    "    import os\n",
    "    self.working_dir = os.getcwd()\n",
    "  def back(self):\n",
    "        import os\n",
    "        os.chdir(self.working_dir)\n",
    "    \n",
    "    \n",
    "conf = configs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa1b18d-87f7-4753-8663-feaab6e2eec5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preparation of storage hierarchy \n",
    "\n",
    "At this moment the following file structure is presented:\n",
    "- ddG_notebook.ipynb\n",
    "- PDB_filename.pdb\n",
    "- __img__\n",
    "    - some illustrative images\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6d446e-f73f-47cb-903d-589f15bc9435",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cleaning PDB file\n",
    "Let's prepare our temporary __file structure hierarchy__ and clean protein file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d80e90-bb98-40e3-89d2-ddfc2733be5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparation(conf):\n",
    "    name, ntraj = conf.PDB_filename, conf.ntraj\n",
    "    import os\n",
    "    current_dir = os.getcwd()\n",
    "    if not os.path.exists(conf.jobname):\n",
    "        os.mkdir(conf.jobname)\n",
    "    os.chdir(conf.jobname)\n",
    "    pdb_name = name[:-4]\n",
    "    os.system(f'''grep \"^ATOM\" ../{pdb_name}.pdb > {pdb_name}_clean.pdb''')\n",
    "    for i in range(1, ntraj + 1):\n",
    "        if not os.path.exists(str(i)):\n",
    "            os.mkdir(str(i))\n",
    "            os.system(f'touch {str(i)}/stdout.txt')\n",
    "    os.chdir(current_dir)\n",
    "    return 0\n",
    "\n",
    "preparation(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7a32c9-1248-457b-b3ab-c9de87703b1d",
   "metadata": {},
   "source": [
    "The inner structure of __jobname__ directore is following:\n",
    "- __jobname__\n",
    "    - PDB_filename_clean.pdb\n",
    "    - __$i^{th}$ trajectory folder__\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f25d17-13ce-4b81-bc4a-33487b9dfe20",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Relaxation\n",
    "In the next cell we will initialize two funcitons.\n",
    "\n",
    "The function __relax_job__ is providing relaxiation of protein structure.\n",
    "\n",
    "def __run_relax_job_parallel__ is wrapper function for running calculation in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb28a2c-7023-4f46-9d72-96926451c934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relax_job(args):\n",
    "    name_clean, nstruct, scorefxn_name, dest = args\n",
    "    import os\n",
    "    import logging\n",
    "    current_dir = os.getcwd()\n",
    "    os.chdir(dest)\n",
    "    logging.basicConfig(filename='stdout.txt', level=logging.INFO)\n",
    "    import pyrosetta\n",
    "    pyrosetta.init()\n",
    "    pose = pyrosetta.pose_from_pdb('../' + name_clean)\n",
    "    scorefxn = pyrosetta.create_score_function(scorefxn_name)\n",
    "    xml = pyrosetta.rosetta.protocols.rosetta_scripts.XmlObjects.create_from_string(\"\"\"\n",
    "    <ROSETTASCRIPTS>\n",
    "        <SCOREFXNS>\n",
    "        <ScoreFunction name=\"SFX1\" weights=\"ref2015_cart\">\n",
    "           <Reweight scoretype=\"coordinate_constraint\" weight=\"1.0\"/>\n",
    "        </ScoreFunction>\n",
    "        </SCOREFXNS>\n",
    "        <RESIDUE_SELECTORS>\n",
    "        </RESIDUE_SELECTORS>\n",
    "        <TASKOPERATIONS>\n",
    "        </TASKOPERATIONS>\n",
    "        <FILTERS>\n",
    "        </FILTERS>\n",
    "        <MOVERS>\n",
    "           <AtomCoordinateCstMover name=\"coord_cst\" />\n",
    "           <FastRelax name=\"relax\" cartesian=\"true\" scorefxn=\"SFX1\" />\n",
    "        </MOVERS>\n",
    "        <APPLY_TO_POSE/>\n",
    "        <PROTOCOLS>\n",
    "           <Add mover=\"coord_cst\" />\n",
    "           <Add mover=\"relax\" />\n",
    "        </PROTOCOLS>\n",
    "    </ROSETTASCRIPTS>\n",
    "    \"\"\").get_mover(\"ParsedProtocol\")\n",
    "    \n",
    "    working_dir = os.getcwd()\n",
    "    output_dir = dest\n",
    "    jd = pyrosetta.toolbox.py_jobdistributor.PyJobDistributor(pdb_name=name_clean[:-4], nstruct=nstruct, scorefxn=scorefxn)\n",
    "    jd.native_pose = pose\n",
    "    while not jd.job_complete:\n",
    "        test_pose = pose.clone()\n",
    "        xml.apply(test_pose)\n",
    "        jd.output_decoy(test_pose)\n",
    "    os.chdir(current_dir)\n",
    "    return 0\n",
    "\n",
    "\n",
    "def run_relax_job_parallel(conf):\n",
    "    name, nstruct, scorefxn_name, num_th = conf.PDB_filename, conf.nstruct, conf.relax_scorefxn, conf.num_threads\n",
    "    name = name[:-4] + '_clean.pdb'\n",
    "    ntraj = conf.ntraj\n",
    "    if not conf.coord_cst:\n",
    "        conf.jobname = conf.jobname + '_without_cst'\n",
    "        preparation(conf)\n",
    "    from multiprocessing.pool import Pool\n",
    "    import os\n",
    "    os.chdir(conf.jobname)\n",
    "    args = [(name, nstruct, scorefxn_name, str(i)) for i in range(1, ntraj + 1)]\n",
    "    with Pool(num_th) as pool:\n",
    "        pool.map(relax_job, args, chunksize=1)\n",
    "    os.chdir('../')\n",
    "    if not conf.coord_cst:\n",
    "        conf.jobname = conf.jobname[:-12]\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1046202f-942a-4272-a83a-b844661c8fd3",
   "metadata": {},
   "source": [
    "Now, we will run relaxiation of structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395b3389-0164-449d-bc16-157dc05cba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_relax_job_parallel(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511574bf-d4d8-4356-aa54-69be0ac080e4",
   "metadata": {},
   "source": [
    "Inside the temporary folder, that was created at the begining we have __ntraj__ number of folders, and in each folder __nstruct__ PDBs. Additionally, there are score files with extension _*.fasc_.\n",
    "\n",
    "- __jobname__\n",
    "    - PDB_filename_clean.pdb\n",
    "    - __$i^{th}$ trajectory folder__\n",
    "        - stdout.txt\n",
    "        - PDB_filename_*.pdb\n",
    "        - PDB_filename.fasc\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9d782b-6228-4c6d-9b5a-5672b4b72937",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code here relax without coordinate constraints\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088880ce-d674-4e00-8368-1027d07fc579",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Scoring\n",
    "We have to choose the structure with the lowest energy score measured in Rosetta Energy Units (REU). \n",
    "The following function is parsing all generated _*.fasc_. score files and return __the path__ to PDB with lowest energy.\n",
    "\n",
    "We will store the returned path as an atribute of __config class__ object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1292fde7-d3c8-44d9-8c14-837de27a4354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores():\n",
    "    conf.back()\n",
    "    import pandas as pd\n",
    "    import glob\n",
    "    import os\n",
    "    os.chdir(conf.jobname)\n",
    "    dall_scores = pd.DataFrame(columns = ['description', 'total_score'])\n",
    "    for f in glob.glob('*/*.fasc'):\n",
    "        pth = str(f).split('/')[0]\n",
    "        with open(f, 'r') as file:\n",
    "            tmp = pd.DataFrame()\n",
    "            for line in file.readlines():\n",
    "                total_score = float(line[line.find('total_score'):line.find('\"yhh_planarity')].split(':')[1].strip()[:-1])\n",
    "                name_decoy = line[line.find(\"decoy\"):line.find(', \"filename\"')].split(':')[-1].split('\"')[1]\n",
    "                dic = {'description': [pth + '/' + name_decoy], 'total_score':[total_score]}\n",
    "                tmp = pd.DataFrame(dic)\n",
    "                dall_scores = pd.concat([dall_scores, tmp], ignore_index = True)\n",
    "\n",
    "    dres = dall_scores[dall_scores.total_score == dall_scores.total_score.min()]\n",
    "    source  = list(dres.description)[0]\n",
    "    pdb = source.split('/')[1]\n",
    "    if not os.path.exists('mutations'):\n",
    "        os.mkdir('mutations')\n",
    "    target = \"mutations/relaxed_\"  + pdb\n",
    "    os.system(f'cp {source} {target}')\n",
    "    os.chdir('../')\n",
    "    return target.split('/')[-1], dall_scores.total_score.min()\n",
    "\n",
    "\n",
    "conf.cleanaxed_pdb, min_REU = get_scores()\n",
    "print((conf.cleanaxed_pdb, min_REU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e59ce9a-9f19-4c36-a8ab-f3fdbc14ab52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d68594-3a9a-430b-89fa-5b621eb6ce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Bio.PDB\n",
    "import os\n",
    "\n",
    "start_id = 1\n",
    "end_id   = 999\n",
    "atoms_to_be_aligned = range(start_id, end_id + 1)\n",
    "\n",
    "# Start the parser\n",
    "pdb_parser = Bio.PDB.PDBParser(QUIET = True)\n",
    "\n",
    "# Get the structures\n",
    "ref_structure = pdb_parser.get_structure(\"reference\", f'{conf.jobname}/{conf.PDB_filename[:-4]}_clean.pdb')\n",
    "sample_structure = pdb_parser.get_structure(\"sample\", f'{conf.jobname}/mutations/{conf.cleanaxed_pdb}')\n",
    "\n",
    "\n",
    "ref_model    = ref_structure[0]\n",
    "sample_model = sample_structure[0]\n",
    "\n",
    "# Make a list of the atoms (in the structures) you wish to align.\n",
    "# In this case we use CA atoms whose index is in the specified range\n",
    "ref_atoms = []\n",
    "sample_atoms = []\n",
    "\n",
    "# Iterate of all chains in the model in order to find all residues\n",
    "for ref_chain in ref_model:\n",
    "  # Iterate of all residues in each model in order to find proper atoms\n",
    "  for ref_res in ref_chain:\n",
    "    # Check if residue number ( .get_id() ) is in the list\n",
    "    if ref_res.get_id()[1] in atoms_to_be_aligned:\n",
    "      # Append CA atom to list\n",
    "      ref_atoms.append(ref_res['CA'])\n",
    "\n",
    "# Do the same for the sample structure\n",
    "for sample_chain in sample_model:\n",
    "  for sample_res in sample_chain:\n",
    "    if sample_res.get_id()[1] in atoms_to_be_aligned:\n",
    "      sample_atoms.append(sample_res['CA'])\n",
    "\n",
    "# Now we initiate the superimposer:\n",
    "super_imposer = Bio.PDB.Superimposer()\n",
    "super_imposer.set_atoms(ref_atoms, sample_atoms)\n",
    "super_imposer.apply(sample_model.get_atoms())\n",
    "\n",
    "# Print RMSD:\n",
    "print('The calculated RMSD is:')\n",
    "print (str(super_imposer.rms) + ' Å')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf7d412-2bcf-4b47-96e8-8bfbde99916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import py3Dmol\n",
    "\n",
    "view=py3Dmol.view()\n",
    "#The following lines are used to add the addModel class\n",
    "#to read the PDB files of chain Clean and Relaxed\n",
    "view.addModel(open(f'{conf.jobname}/{conf.PDB_filename[:-4]}_clean.pdb', 'r').read(),'pdb')\n",
    "\n",
    "view.addModel(open(f'{conf.jobname}/mutations/{conf.cleanaxed_pdb}', 'r').read(),'pdb')\n",
    "#Zooming into all visualized structures \n",
    "view.zoomTo()\n",
    "#Here we set the background color as white\n",
    "view.setBackgroundColor('white')\n",
    "#Here we set the visualization style for Clean and Relaxed\n",
    "view.setStyle({'model': 0},{'cartoon': {'color':'purple'}})\n",
    "view.setStyle({'model': 1},{'cartoon': {'color':'yellow'}})\n",
    "\n",
    "view.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7471c1d2-c98c-40ab-94c2-48ca293893b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exercise: plot scatter_plot RMSD vs total score, \n",
    "### and highlight the dot with the lowest energy\n",
    "\n",
    "# Solution\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aae8c30-0c28-41df-a938-41dfa454037c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Mutfile's preparation\n",
    "From this point, we obtain the relaxed protein structure that prepared for introducing mutations and analyzing them.\n",
    "\n",
    "Let's create a little bit more new subfolders and put __mutfile__'s for as an instruction for PyRosetta mutation script.\n",
    "<br><br>\n",
    "\n",
    "Each __mutfile__ consists the following lines:\n",
    "\n",
    "total 1 &emsp;# this is the total number of mutations being made.\n",
    "<br>\n",
    "1 &emsp; &emsp;&emsp;#the number of mutations\n",
    "<br>\n",
    "G 1 A &emsp; # the wild-type aa, the residue number, and the mutant aa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeafc18-9148-4783-a78f-c94a132eb379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def mutfiles_preparation(conf):\n",
    "    conf.back()\n",
    "    os.chdir(f'{conf.jobname}/mutations')\n",
    "    mut = conf.mut\n",
    "    aa_list = conf.aa_list\n",
    "    mutations = []\n",
    "    for aa in range(0, len(mut)):\n",
    "        pos = mut[aa]\n",
    "        AA = mut[aa][0]\n",
    "        if not os.path.exists(pos):\n",
    "            os.makedirs(pos)\n",
    "        for m in aa_list:\n",
    "            if m != AA:\n",
    "                mutation = pos+m\n",
    "                mutations.append(mutation)\n",
    "                if not os.path.exists(pos+\"/\"+mutation):\n",
    "                    os.makedirs(pos+\"/\"+mutation)\n",
    "                with open(pos+\"/\"+mutation+\"/mutfile\",'w') as mut_file:\n",
    "                    mut_file.write(\"total 1\\n\")\n",
    "                    mut_file.write(\"1\\n\")\n",
    "                    mut_file.write(\"%s %d %s\\n\" %(AA, int(mut[aa][1:]), m))\n",
    "    os.chdir('../../')\n",
    "    return 0\n",
    "\n",
    "\n",
    "mutfiles_preparation(conf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58031ee0-c6e3-4b12-a599-7e1c5e79d6f3",
   "metadata": {},
   "source": [
    "The __jobname__ folder structure now is looking like this:\n",
    "\n",
    "- __jobname__\n",
    "    - PDB_filename_clean.pdb\n",
    "    - __$i^{th}$ trajectory folder__\n",
    "        - stdout.txt\n",
    "        - PDB_filename_*.pdb\n",
    "        - PDB_filename.fasc\n",
    "    - __mutations__\n",
    "        - relaxed_PDB_filename_clean_$i$.pdb\n",
    "        - __$i^{th}$__ mutation folder along __mut__ array\n",
    "            - __$j^{th}$__ resulted mut folder along __aa_list__\n",
    "                - mutfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f9fb3d-9399-4d94-a8ec-69d6b962fc5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## $\\Delta\\Delta G$ calculation\n",
    "In the next cell we will initialize two funciton.\n",
    "\n",
    "def __ddg_job__ is made for estimating $\\Delta\\Delta G$ per one-point mutation. \n",
    "\n",
    "def __run_ddg_calc_parallel__ is wrapper function for running calculation in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa37497e-ee3b-4720-89ac-5c1445716209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddg_job(args):\n",
    "    pdb_name, py_flags, dest = args\n",
    "    import os\n",
    "    import logging\n",
    "    current_dir = os.getcwd()\n",
    "    os.chdir(dest)\n",
    "    logging.basicConfig(filename='stdout.txt', level=logging.INFO)\n",
    "    import pyrosetta\n",
    "    \n",
    "    pyrosetta.init(py_flags)\n",
    "    pose = pyrosetta.pose_from_pdb('../../' + pdb_name)\n",
    "    pyrosetta.rosetta.protocols.ddg.CartesianddG.run(pose)\n",
    "    os.chdir(current_dir)\n",
    "    return 0\n",
    "\n",
    "def run_ddg_calc_parallel(conf):\n",
    "    conf.back()\n",
    "    import os \n",
    "    os.chdir(f'{conf.jobname}/mutations')\n",
    "    name = conf.cleanaxed_pdb\n",
    "    num_th = conf.num_threads\n",
    "    import glob\n",
    "    args = [(name, conf.py_flags, x[:-7]) for x in glob.glob('*/*/mutfile')]\n",
    "    from multiprocessing.pool import Pool\n",
    "    with Pool(num_th) as pool:\n",
    "        pool.map(ddg_job, args, chunksize=1)\n",
    "    os.chdir('../../')\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df49d63-3d47-49e1-a489-a2f5c8be55a9",
   "metadata": {},
   "source": [
    "Now, we will run $\\Delta\\Delta G$ calculation for all one-point mutations that were selected in __config__ class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44580604-0781-4bea-897b-2718d485c56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ddg_calc_parallel(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ba0b80-d6d8-4f84-afe7-2588e7b1ba7e",
   "metadata": {},
   "source": [
    "Let's analyze just generated outputs. We are intrested in __mutfile.ddg__  files.\n",
    "\n",
    "The __jobname__ folder structure now is looking like this:\n",
    "\n",
    "- __jobname__\n",
    "    - PDB_filename_clean.pdb\n",
    "    - __$i^{th}$ trajectory folder__\n",
    "        - stdout.txt\n",
    "        - PDB_filename_*.pdb\n",
    "        - PDB_filename.fasc\n",
    "    - __mutations__\n",
    "        - relaxed_PDB_filename_clean_$i$.pdb\n",
    "        - __$i^{th}$__ mutation folder along __mut__ array\n",
    "            - __$j^{th}$__ resulted mut folder along __aa_list__\n",
    "                - mutfile\n",
    "                - mutfile.ddg\n",
    "                - stdout.txt\n",
    "    \n",
    "Based on the information from __mutfile.ddg__, the $\\Delta\\Delta G$ will be calculated as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\Large{\\Delta}{\\Delta}G={\\frac {\\sum_{i}^{} MUT\\_total\\_score_{i} \\\\}{ddg\\_iterations} }-{\\frac {\\sum_{i}^{} WT\\_total\\_score_{i} \\\\}{ddg\\_iterations} }\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a7c8ab-6b8d-45ea-8dc0-e14229ae16ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Analyzing \n",
    "The bellow function generates __*.csv__ file in root directory with $\\Delta\\Delta G$ values measured in REU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1070b581-856e-4d3d-b763-12bdcb3786a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_ssm(conf):\n",
    "    conf.back()\n",
    "    mut = conf.mut\n",
    "    aa_list = conf.aa_list\n",
    "    import os\n",
    "    import glob\n",
    "    import numpy as np\n",
    "    os.chdir(f'{conf.jobname}/mutations')\n",
    "    def nice_order(aa_l):\n",
    "        nice_order_for_heatmap  = [\"G\",\"P\",\"E\",\"D\",\"R\",\"K\",\"H\",\"Q\",\"N\",\"T\",\"S\",\"Y\",\"W\",\"F\",\"M\",\"C\",\"I\",\"L\",\"V\",\"A\"]\n",
    "        aa_list_for_an = nice_order_for_heatmap.copy()\n",
    "        for item in nice_order_for_heatmap:\n",
    "            if item not in aa_l:\n",
    "                aa_list_for_an.remove(item)\n",
    "        return aa_list_for_an\n",
    "    aa_list = nice_order(aa_list)\n",
    "    ala_scan = {}\n",
    "    ssm = np.zeros([len(aa_list), len(mut)], dtype=float)\n",
    "    pdb_name = conf.cleanaxed_pdb[:-4]\n",
    "\n",
    "    for aa in range(0, len(mut)):\n",
    "        pos = mut[aa]\n",
    "        AA = mut[aa][0]\n",
    "        for i in range(0, len(aa_list)):\n",
    "            amino_acid = aa_list[i]\n",
    "            if AA != amino_acid:\n",
    "                mutation = mut[aa]+amino_acid\n",
    "                n_WT = 0\n",
    "                n_MUT = 0\n",
    "                score_WT = 0\n",
    "                score_MUT = 0\n",
    "                with open(pos+\"/\"+mutation+\"/mutfile.ddg\", 'r') as mutfile:\n",
    "                    for line in mutfile:\n",
    "                        if \"WT\" in line:\n",
    "                            score = float(line.split()[3])\n",
    "                            n_WT += 1\n",
    "                            score_WT += score\n",
    "                        elif \"MUT_\" in line:\n",
    "                            score = float(line.split()[3])\n",
    "                            n_MUT += 1\n",
    "                            score_MUT += score\n",
    "                score_WT = score_WT/n_WT\n",
    "                score_MUT = score_MUT/n_MUT\n",
    "                ddG = score_MUT - score_WT\n",
    "                ssm[i,aa] = float(ddG)\n",
    "\n",
    "\n",
    "    np.savetxt(\"../../SSM_ddg.csv\", ssm, delimiter=\",\")\n",
    "    os.chdir('../../')\n",
    "    return 0\n",
    "analyze_ssm(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3d4b73-c832-4b88-9d00-6569739d6c6f",
   "metadata": {},
   "source": [
    "Once the *SSM_ddg.csv* file is obtained, we can finally plot heatmap and detect which mutation and where could stabilize the protein."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17660b34-1683-416e-aa82-60769ee1d835",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualizing Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2094004-e3df-4584-8596-a4577a1dba78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "\n",
    "def plot_heatmap(conf):\n",
    "    conf.back()\n",
    "    def nice_order(aa_l):\n",
    "        nice_order_for_heatmap  = [\"G\",\"P\",\"E\",\"D\",\"R\",\"K\",\"H\",\"Q\",\"N\",\"T\",\"S\",\"Y\",\"W\",\"F\",\"M\",\"C\",\"I\",\"L\",\"V\",\"A\"]\n",
    "        aa_list_for_an = nice_order_for_heatmap.copy()\n",
    "        for item in nice_order_for_heatmap:\n",
    "            if item not in aa_l:\n",
    "                aa_list_for_an.remove(item)\n",
    "        return aa_list_for_an\n",
    "    aa_list = nice_order(conf.aa_list)\n",
    "    mut = conf.mut\n",
    "    df_ddg = pd.read_csv('SSM_ddg.csv', header=None)    \n",
    "    rows = {i:aa_list[i] for i in range(len(aa_list))}\n",
    "    columns = {i:mut[i] for i in range(len(mut))}\n",
    "    \n",
    "    df_ddg = df_ddg.rename(columns=columns)\n",
    "    df_ddg = df_ddg.rename(index=rows)\n",
    "    minc = df_ddg.min().min()\n",
    "    range_color = [minc, (-1.5) * minc]\n",
    "    sns.set (rc = {'figure.figsize':(15, 10)})\n",
    "    ax = sns.heatmap(df_ddg,  cmap=\"jet\", annot=True, fmt=\".1f\",linewidth=.5, vmin = minc, vmax = (-1.5) * minc, \\\n",
    "                     cbar_kws={'label': 'ΔΔG', 'orientation': 'vertical'})#, annot_kws={\"size\": 20}\n",
    "    ax.set(xlabel=\"Mutations\", ylabel=\"Amino Acid\")\n",
    "    ax.xaxis.tick_top()\n",
    "%matplotlib inline\n",
    "plot_heatmap(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a7b982-5bee-42ce-a732-9c9f9403d073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b587233a-0e9d-4712-b9d4-dd5fa80a3102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150cb710-9536-4489-8e8c-797813b80559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e297e63-99f0-4702-9975-b39a8ce2a31d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e7bef4-5964-4861-8b49-59f0142ea25b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8d3ed8b-52c9-4b70-a99d-23c9c1c00eb2",
   "metadata": {},
   "source": [
    "## Exercise 2. \n",
    "PDB 2WH6\n",
    "\n",
    "\n",
    "The positions to mutate: Leu  at 169, Ile at 172, Phe at 176\n",
    "\n",
    "Candidates for investigation: A, I, L, M, F, H, V\n",
    "\n",
    "__Hint__: you have to create a separate _utils_ Python file with all previously used functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec91749-37dd-4b6f-9ae4-7479f326350f",
   "metadata": {},
   "source": [
    "the $\\Delta\\Delta G$ will be calculated as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\Large{\\Delta}{\\Delta}G_{interface}={\\frac {\\sum_{i}^{} COMPLEX\\_score_{i} \\\\}{ddg\\_iterations} }-{\\frac {\\sum_{i}^{} SEPARATE\\_score_{i} \\\\}{ddg\\_iterations} }\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437223c5-e42d-464b-9f96-1aed7703198f",
   "metadata": {},
   "source": [
    "Download the structure by command: wget https://files.rcsb.org/download/2WH6.pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071c0332-39e6-4de0-82ef-566604f4a014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "class configs(object):\n",
    "  def __init__(self):\n",
    "\n",
    "    self.PDB_filename =  CHANGE ME\n",
    "    self.mut = CHANGE ME\n",
    "    self.aa_list = CHANGE ME\n",
    "    self.jobname = CHANGE ME\n",
    "    \n",
    "    self.num_threads = 0\n",
    "    self.ntraj = 1\n",
    "    self.nstruct = 2\n",
    "    self.relax_scorefxn = 'ref2015_cart'\n",
    "    self.ddg_iterations = 3\n",
    "    self.force_iterations = False\n",
    "    self.ddg_score_cutoff = 1.0\n",
    "    self.ddg_dump_pdbs = True\n",
    "    self.ddg_bbnbrs = 1\n",
    "    self.fa_max_dis = 9.0\n",
    "    self.ddg_scorefxn = 'ref2015_cart'\n",
    "    \n",
    "    import os\n",
    "    if not os.path.exists(self.PDB_filename):\n",
    "        raise Exception(f\"Sorry, the file with name {self.PDB_filename[:-4]} was not found.\")\n",
    "    \n",
    "    if self.num_threads == 0:\n",
    "        import os \n",
    "        nslots = int(os.environ['SLURM_CPUS_PER_TASK'])\n",
    "        self.num_threads = nslots\n",
    "    self.coord_cst = True\n",
    "    py_flags = \"-ddg:mut_file mutfile -ddg:iterations \"\n",
    "    py_flags += str(self.ddg_iterations) \n",
    "    py_flags += \" -force_iterations \"\n",
    "    py_flags += str(self.force_iterations).lower()\n",
    "    py_flags += \" -ddg::score_cutoff \"\n",
    "    py_flags += str(self.ddg_score_cutoff)\n",
    "    py_flags += \" -ddg::cartesian -ddg::dump_pdbs \"\n",
    "    py_flags += str(self.ddg_dump_pdbs).lower()\n",
    "    py_flags += \" -ddg:bbnbrs \"\n",
    "    py_flags += str(self.ddg_bbnbrs)\n",
    "    py_flags += \" -fa_max_dis \"\n",
    "    py_flags += str(self.fa_max_dis)\n",
    "    py_flags += \" -score:weights \"\n",
    "    py_flags += str(self.ddg_scorefxn)\n",
    "    py_flags += \".wts\"\n",
    "    self.py_flags = py_flags\n",
    "    \n",
    "    \n",
    "conf = configs()\n",
    "\n",
    "preparation(conf)\n",
    "run_relax_job_parallel(conf)\n",
    "conf.cleanaxed_pdb, _ = get_scores()\n",
    "mutfiles_preparation(conf)\n",
    "run_ddg_calc_parallel(conf)\n",
    "analyze_ssm(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb9cf43-60ae-4f64-920b-17aa54c7300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Excercise 2.1. Extract chain B from PDB file.\n",
    "\n",
    "#Solution:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f3c23d-0443-4c03-9fce-f605feff02c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Excercise 2.2.1 Visualize Chains with different colours of chains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beee9a89-d0ce-460f-99a9-ae442b685fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Excercise 2.2.2 The same with surfaces\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9269e45d-f803-4641-b394-55a6208239fe",
   "metadata": {},
   "source": [
    "## FastDesign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13697d2b-9eba-4285-babd-957b56703317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import argparse\n",
    "import pyrosetta\n",
    "\n",
    "def Fast_Design_RUN(target=None, filename=None, run_num=None):\n",
    "    # Initialize PyRosetta with custom flags\n",
    "    pyrosetta.init('''\n",
    "        -relax:default_repeats 5\n",
    "        -relax:constrain_relax_to_start_coords\n",
    "        -relax:coord_constrain_sidechains\n",
    "        -relax:ramp_constraints false\n",
    "        -score::hbond_params correct_params\n",
    "        -no_his_his_pairE\n",
    "        -extrachi_cutoff 1\n",
    "        -multi_cool_annealer 10\n",
    "        -ex1 -ex2\n",
    "        -use_input_sc\n",
    "        -flip_HNQ\n",
    "        -ignore_unrecognized_res\n",
    "        -relax:coord_cst_stdev 0.5\n",
    "    ''')\n",
    "\n",
    "    # Clean pdb\n",
    "    pyrosetta.toolbox.cleaning.cleanATOM(filename)\n",
    "    # Load the cleaned PDB\n",
    "    base = os.path.splitext(filename)[0]\n",
    "    btl = pyrosetta.pose_from_pdb(f\"{base}.clean.pdb\")\n",
    "    original_pose = btl.clone()\n",
    "    scorefxn = pyrosetta.get_fa_scorefxn()\n",
    "    print(\"Original score: \", scorefxn.score(btl))\n",
    "\n",
    "    # Setup directory structure\n",
    "    main_dir = os.getcwd()\n",
    "    output_dir = os.path.join(\"Outputs\", f\"mutating_res{target}\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    os.chdir(output_dir)\n",
    "\n",
    "    # FastRelax \n",
    "    fr = pyrosetta.rosetta.protocols.relax.FastRelax()\n",
    "    fr.set_scorefxn(scorefxn)\n",
    "    fr.apply(btl)\n",
    "    print(\"Relaxed score: \", scorefxn.score(btl))\n",
    "    relaxed_pose = btl.clone()\n",
    "    btl.dump_pdb(f\"relaxed_{run_num}_{filename}\")\n",
    "\n",
    "    # Job distributor for designs\n",
    "    job = pyrosetta.toolbox.py_jobdistributor.PyJobDistributor(f'{base}_design_{run_num}', 8, scorefxn)\n",
    "    job.native_pose = original_pose\n",
    "    pose = pyrosetta.Pose()\n",
    "\n",
    "    while not job.job_complete:\n",
    "        pose.assign(relaxed_pose)\n",
    "        fastdesign(pose, target)# design\n",
    "        i = print_mutations(original_pose, pose, job.current_name) #prints the mutations\n",
    "        if len(i) == 0:\n",
    "            continue\n",
    "        fr.apply(pose) # relax\n",
    "        print(\"FinalScore: \", scorefxn.score(pose))\n",
    "        job.output_decoy(pose)\n",
    "\n",
    "    os.chdir(main_dir)\n",
    "\n",
    "    \n",
    "def fastdesign(pose, target):\n",
    "    \"\"\"Setups the design around protocol and design the pose accordingly.\"\"\"\n",
    "    scorefxn = pyrosetta.get_fa_scorefxn()\n",
    "    #Selectors\n",
    "    target_residue = pyrosetta.rosetta.core.select.residue_selector.ResidueIndexSelector(str(target))\n",
    "    design_radius = random.randint(8, 12)\n",
    "    design_shell = pyrosetta.rosetta.core.select.residue_selector.NeighborhoodResidueSelector(target_residue, design_radius, False)\n",
    "    repack_shell = pyrosetta.rosetta.core.select.residue_selector.NeighborhoodResidueSelector(target_residue, design_radius + 4, True)\n",
    "    # Important residues that should not be designed\n",
    "    imp_residues = \"2,7,8,9,10,11,12,13,14,15,16,17,18\"#,19,20,37,42,45,48,51,82,97,105,107,120,141,142,149,158,194,201,209,218,226,230,235\"\n",
    "    imp_residue_selector = pyrosetta.rosetta.core.select.residue_selector.ResidueIndexSelector(imp_residues)\n",
    "\n",
    "    # Setup TaskFactory\n",
    "    tf = pyrosetta.rosetta.core.pack.task.TaskFactory()\n",
    "    # Task operations\n",
    "    tf.push_back(pyrosetta.rosetta.core.pack.task.operation.InitializeFromCommandline())\n",
    "    tf.push_back(pyrosetta.rosetta.core.pack.task.operation.IncludeCurrent())\n",
    "    tf.push_back(pyrosetta.rosetta.core.pack.task.operation.NoRepackDisulfides())\n",
    "    tf.push_back(pyrosetta.rosetta.core.pack.task.operation.OperateOnResidueSubset(\n",
    "        pyrosetta.rosetta.core.pack.task.operation.RestrictToRepackingRLT(), imp_residue_selector, False))\n",
    "    tf.push_back(pyrosetta.rosetta.core.pack.task.operation.OperateOnResidueSubset(\n",
    "        pyrosetta.rosetta.core.pack.task.operation.RestrictToRepackingRLT(), design_shell, True))\n",
    "    tf.push_back(pyrosetta.rosetta.core.pack.task.operation.OperateOnResidueSubset(\n",
    "        pyrosetta.rosetta.core.pack.task.operation.PreventRepackingRLT(), repack_shell, True))\n",
    "    \n",
    "    # Setup MoveMap for fixed backbone\n",
    "    mm = pyrosetta.rosetta.core.kinematics.MoveMap()\n",
    "    mm.set_bb(False)\n",
    "    mm.set_chi(True)\n",
    "    mm.set_jump(True)\n",
    "        \n",
    "    # # Setup MoveMap for flexible backbone\n",
    "    # mm = pyrosetta.rosetta.core.kinematics.MoveMap()\n",
    "    # mm.set_bb(True)\n",
    "    # mm.set_chi(True)\n",
    "    # mm.set_jump(True)\n",
    "\n",
    "    # Mover Setup\n",
    "    fd = pyrosetta.rosetta.protocols.denovo_design.movers.FastDesign(scorefxn_in=scorefxn, script_file=\"MonomerDesign2019\")\n",
    "    fd.set_task_factory(tf)\n",
    "    fd.set_movemap(mm)\n",
    "    fd.set_scorefxn(scorefxn)\n",
    "    fd.apply(pose)    \n",
    "    print(\"Design: \", scorefxn.score(pose))\n",
    "    print_radius(design_radius)\n",
    "\n",
    "def print_mutations(original_pose, designed_pose, job_name):\n",
    "    \"\"\"Prints and logs the mutations between the original and designed poses.\"\"\"\n",
    "    original_seq = original_pose.sequence()\n",
    "    designed_seq = designed_pose.sequence()\n",
    "    mutations = []\n",
    "    for i in range(0, original_pose.total_residue()):\n",
    "        if original_seq[i] != designed_seq[i]:\n",
    "            resid = original_pose.pdb_info().pose2pdb(i+1)\n",
    "            mutations.append(f\"{original_seq[i]}{resid.split()[0]}{designed_seq[i]}\")\n",
    "            # mutations.append(f\"{original_seq[i]}{i+1}{designed_seq[i]}\")\n",
    "    mutations_str = f\"{job_name} - Mutations: \" + \", \".join(mutations)\n",
    "    print(mutations_str)\n",
    "    with open(\"mutations.txt\", \"a\") as mutation_file:\n",
    "        if not len(mutations) == 0:\n",
    "            mutation_file.write(mutations_str + \"\\n\")\n",
    "        else:\n",
    "            mutation_file.write(\"\\n\")\n",
    "        mutation_file.close()\n",
    "    return mutations\n",
    "\n",
    "def print_radius(radius):\n",
    "    \"\"\"Prints and logs the radius of design shell and repack shell.\"\"\"\n",
    "    radius_str = f\"Design shell: {radius}A      Repack shell: {radius+4}A\"\n",
    "    print(radius_str)\n",
    "    with open(\"radius.txt\", \"a\") as radius_file:\n",
    "        radius_file.write(radius_str + \"\\n\")\n",
    "        radius_file.close()            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c8e822-4b98-4189-8f13-11fbf929e1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fast_Design_RUN(target= INTEGER NUM of RES, filename=STR FILENAME of PDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecc0188-8480-43a7-b8cc-e17951c5ec8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b89eee-571f-4e70-bcaa-f7fdee04fb94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fcccc1-2b40-4de0-ae32-58b8000e2966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a751862-d77c-4efe-a662-7f94918a04c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tiny benchmark (bonus)\n",
    "Let's go through tiny benchmark and compare Pyrosetta cleaning function with bash  grep funciton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af124039-fc63-45ba-8056-5865762d44bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import datetime\n",
    "from multiprocessing import Process\n",
    "n_repeats = 200\n",
    "\n",
    "if not os.path.exists('small_benchmark'):\n",
    "    os.mkdir('small_benchmark')\n",
    "if not os.path.exists(f'small_benchmark/{conf.PDB_filename}'):\n",
    "    os.system(f'cp {conf.PDB_filename} ./small_benchmark/{conf.PDB_filename}')\n",
    "    \n",
    "def pyrosetta_cleaning():\n",
    "    import logging\n",
    "    logging.basicConfig(filename='small_benchmark/stdout.txt', level=logging.INFO)\n",
    "    import pyrosetta\n",
    "    pyrosetta.init(\"-mute all\")\n",
    "    start = time.time()\n",
    "    for i in range(n_repeats):\n",
    "        pose = pyrosetta.pose_from_pdb(f\"small_benchmark/{conf.PDB_filename}\")\n",
    "        pyrosetta.toolbox.cleanATOM(f\"small_benchmark/{conf.PDB_filename}\")\n",
    "    end = time.time()\n",
    "    import os\n",
    "    duration_pyrosetta = str(end - start)\n",
    "    os.system(f'echo {duration_pyrosetta} > small_benchmark/pyrosetta_cleaning.txt')\n",
    "\n",
    "def grep_cleaning():\n",
    "    start = time.time()\n",
    "    for i in range(n_repeats):\n",
    "        os.system(f'''grep \"^ATOM\" small_benchmark/{conf.PDB_filename} > small_benchmark/{conf.PDB_filename[:-4]}_clean.pdb''')\n",
    "    end = time.time()\n",
    "    return end - start\n",
    "Proc = Process(target=pyrosetta_cleaning)\n",
    "Proc.start()\n",
    "Proc.join()\n",
    "\n",
    "duration_pyrosetta = float(open('small_benchmark/pyrosetta_cleaning.txt','r').readline())\n",
    "duration_grep = grep_cleaning()\n",
    "\n",
    "print(\"\\n\")\n",
    "print('PyRosetta cleaning for ' + str(n_repeats) + \\\n",
    "      ' repeats: ' + \"{:.2f}\".format(round(duration_pyrosetta, 2)) + \" seconds.\")\n",
    "print('bash grep cleaning for ' + str(n_repeats) + \\\n",
    "      ' repeats: ' +\"{:.2f}\".format(round(duration_grep, 2)) + \" seconds.\")\n",
    "print(\"\\n\\t\" + \"Speed up = \" + str(duration_pyrosetta / duration_grep) + \" times\")\n",
    "Proc.kill()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
